{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOlKRvREyFsuJ9trrs14c5Y"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torchvision\nimport torchvision.transforms\n\n!pip install kornia\nfrom kornia import augmentation as K\nfrom kornia.augmentation import AugmentationSequential\nfrom torch.utils.data import random_split\n\nimport numpy as np\n\nimport os\nimport time\nfrom pathlib import Path\nimport pickle\n\nVERSION = 0.1\n","metadata":{"id":"zNf1AQxVkZdi","executionInfo":{"status":"ok","timestamp":1766743875913,"user_tz":-120,"elapsed":5636,"user":{"displayName":"Gilad Navok","userId":"06092819627906668279"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7fd9b195-abbc-4da1-f986-982016920821","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:17:49.116524Z","iopub.execute_input":"2025-12-26T10:17:49.117343Z","iopub.status.idle":"2025-12-26T10:17:52.191938Z","shell.execute_reply.started":"2025-12-26T10:17:49.117289Z","shell.execute_reply":"2025-12-26T10:17:52.190767Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.2)\nRequirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.10)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->kornia) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->kornia) (3.0.3)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Google drive\ncheckpoint_dir = Path('/content/drive/MyDrive/dl_pj/checkpoints/')\ncheckpoint_dir.mkdir(parents=True, exist_ok=True)\nfrom google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"zNf1AQxVkZdi","executionInfo":{"status":"ok","timestamp":1766743875913,"user_tz":-120,"elapsed":5636,"user":{"displayName":"Gilad Navok","userId":"06092819627906668279"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7fd9b195-abbc-4da1-f986-982016920821","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:17:14.556880Z","iopub.execute_input":"2025-12-26T10:17:14.557175Z","iopub.status.idle":"2025-12-26T10:17:14.604412Z","shell.execute_reply.started":"2025-12-26T10:17:14.557142Z","shell.execute_reply":"2025-12-26T10:17:14.603388Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2625946198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/hostname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;34m'Mounting drive is unsupported in this environment. Use PyDrive2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m' instead. See examples at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Mounting drive is unsupported in this environment. Use PyDrive2 instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2."],"ename":"NotImplementedError","evalue":"Mounting drive is unsupported in this environment. Use PyDrive2 instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# kaggle\ncheckpoint_dir = Path('/kaggle/working/checkpoints/')\ncheckpoint_dir.mkdir(parents=True, exist_ok=True)\ntraining_stats_dir = Path('/kaggle/working/training_stats/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:18:26.442742Z","iopub.execute_input":"2025-12-26T10:18:26.443367Z","iopub.status.idle":"2025-12-26T10:18:26.447071Z","shell.execute_reply.started":"2025-12-26T10:18:26.443335Z","shell.execute_reply":"2025-12-26T10:18:26.446384Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes,kernel_size=1,stride=stride,bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layer = []\n        for s in strides:\n            layer.append(block(self.in_planes, planes, s))\n            self.in_planes = planes\n        return nn.Sequential(*layer)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2, 2, 2, 2])\n","metadata":{"id":"ElgGUpWbrrci","executionInfo":{"status":"ok","timestamp":1766743054230,"user_tz":-120,"elapsed":10,"user":{"displayName":"Gilad Navok","userId":"06092819627906668279"}},"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:18:28.282136Z","iopub.execute_input":"2025-12-26T10:18:28.282418Z","iopub.status.idle":"2025-12-26T10:18:28.469777Z","shell.execute_reply.started":"2025-12-26T10:18:28.282394Z","shell.execute_reply":"2025-12-26T10:18:28.469088Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def get_model_summary(model):\n    num_params = sum(p.numel() for p in model.parameters())\n    total_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n    size_mb = total_bytes / (1024 ** 2)\n    return num_params, size_mb\n\ntotal_params, model_size_mb = get_model_summary(ResNet18())\nprint(f\"Total Parameters: {total_params:,}\")\nprint(f\"Model Size: {model_size_mb:.2f} MB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_accuracy(model, dataloader, device):\n    model.eval() # put in evaluation mode,  turn off Dropout, BatchNorm uses learned statistics\n    total_correct = 0\n    total_images = 0\n    with torch.no_grad():\n        for data in dataloader:\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            images = normalize(images)\n            outputs = model(images)\n            predictions = torch.argmax(outputs, dim=-1)\n            total_images += labels.size(0)\n            total_correct += (predictions == labels).sum().item()\n\n    model_accuracy = total_correct / total_images * 100\n    return model_accuracy\n","metadata":{"id":"k3Z55XXW407W","executionInfo":{"status":"ok","timestamp":1766743013043,"user_tz":-120,"elapsed":4,"user":{"displayName":"Gilad Navok","userId":"06092819627906668279"}},"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:18:31.205155Z","iopub.execute_input":"2025-12-26T10:18:31.205435Z","iopub.status.idle":"2025-12-26T10:18:31.210395Z","shell.execute_reply.started":"2025-12-26T10:18:31.205410Z","shell.execute_reply":"2025-12-26T10:18:31.209699Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Split data set into train-validation-test.\nWe are using 80% train, 20% validation split","metadata":{"id":"kJ7YrZBl6lho"}},{"cell_type":"code","source":"transform = torchvision.transforms.Compose(\n    [torchvision.transforms.ToTensor()]\n)\n\n# 80/20% split\ntrain_val_set = torchvision.datasets.CIFAR10(\n    root='./data',\n    train=True,\n    download=True,\n    transform=transform\n)\n\ntrain_size = int(0.8 * len(train_val_set))\nval_size = len(train_val_set) - train_size\ntrainset, valset = random_split(\n    train_val_set,\n    [train_size, val_size],\n    generator=torch.Generator().manual_seed(42)\n)\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform\n)\n","metadata":{"id":"rkI3-MRt58hj","executionInfo":{"status":"ok","timestamp":1766743016313,"user_tz":-120,"elapsed":1992,"user":{"displayName":"Gilad Navok","userId":"06092819627906668279"}},"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:18:32.916182Z","iopub.execute_input":"2025-12-26T10:18:32.916923Z","iopub.status.idle":"2025-12-26T10:18:55.518672Z","shell.execute_reply.started":"2025-12-26T10:18:32.916893Z","shell.execute_reply":"2025-12-26T10:18:55.518078Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:17<00:00, 9.56MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Hyperparamters\nbatch_size = 128\n\nlr = 0.1\nmomentum = 0.9\nweight_decay = 5e-4\n\nT_max = 200\n\nn_epochs = 200\n\nprint_progress_every = 1\nval_accuracy_storing_threshold = 50\n","metadata":{"id":"Zy87RRrf7Vh6","executionInfo":{"status":"ok","timestamp":1766743919319,"user_tz":-120,"elapsed":2,"user":{"displayName":"Gilad Navok","userId":"06092819627906668279"}},"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:18:58.232855Z","iopub.execute_input":"2025-12-26T10:18:58.233163Z","iopub.status.idle":"2025-12-26T10:18:58.237914Z","shell.execute_reply.started":"2025-12-26T10:18:58.233138Z","shell.execute_reply":"2025-12-26T10:18:58.237309Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmean = torch.tensor([0.4914, 0.4822, 0.4465]).to(device)\nstd = torch.tensor([0.2023, 0.1994, 0.2010]).to(device)\nnormalize = K.Normalize(mean=mean, std=std)\n# define a sequence of augmentations\naug_list = AugmentationSequential(\n    K.RandomHorizontalFlip(p=0.5),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.2),\n    K.RandomResizedCrop(size=(32,32), scale=(0.7, 1.0), p=0.5),\n    normalize,\n    same_on_batch=False\n).to(device)\n\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\nvalloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\nmodel = ResNet18().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n\nstats = {\n    'total_training_time': 0,\n    'loss': [],\n    'time_per_epoch': [0],\n    'total_time_per_epoch': [],\n    'val_accuracy': [],\n    'max_val_accuracy': 0,\n    'allocated_memory': [], # Memory currently used by Tensors\n    'reserved_memory': [], # Memory held by the PyTorch caching allocator\n}\n\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    model.train()\n    iteration_losses = []\n    epoch_start_time = time.time()\n    for inputs, targets in trainloader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n\n        inputs = aug_list(inputs)\n\n        outputs = model(inputs)\n\n        optimizer.zero_grad()\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        iteration_losses.append(loss.item())\n\n    scheduler.step()\n    epoch_end_time = time.time()\n\n    model.eval()\n    val_accuracy = calculate_accuracy(model, valloader, device)\n\n    # Track stats\n    if (epoch % 1) == 0:\n        stats['loss'].append(\n            np.mean(iteration_losses)\n        )\n        stats['val_accuracy'].append(\n            val_accuracy\n        )\n        stats['allocated_memory'].append(torch.cuda.memory_allocated())\n        stats['reserved_memory'].append(torch.cuda.memory_reserved())\n        stats['time_per_epoch'].append(epoch_end_time - epoch_start_time)\n        stats['total_time_per_epoch'].append(time.time() - start_time)\n\n    # Store best model\n    if (val_accuracy > stats['max_val_accuracy']):\n        if (val_accuracy > val_accuracy_storing_threshold):\n            stats['max_val_accuracy'] = val_accuracy\n            print('==> Saving model ...')\n            state = {\n            'net': model.state_dict(),\n            'epoch': epoch,\n            'acc':val_accuracy\n            }\n            save_path = checkpoint_dir / f\"baseline_max_acc_{VERSION}.pth\"\n            torch.save(state, save_path)\n    # Print progress\n    if (epoch % print_progress_every) == 0:\n        print(f\"Epoch {epoch} Loss {stats['loss'][-1]:.3f} Val Acc {stats['val_accuracy'][-1]:.3f}\")\n\n","metadata":{"id":"W45Vot2zvrLE","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:19:00.256204Z","iopub.execute_input":"2025-12-26T10:19:00.256514Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 Loss 2.012 Val Acc 39.020\nEpoch 1 Loss 1.535 Val Acc 47.800\n==> Saving model ...\nEpoch 2 Loss 1.322 Val Acc 58.560\nEpoch 3 Loss 1.136 Val Acc 56.850\n==> Saving model ...\nEpoch 4 Loss 1.000 Val Acc 67.230\n==> Saving model ...\nEpoch 5 Loss 0.846 Val Acc 71.890\nEpoch 6 Loss 0.726 Val Acc 70.930\n==> Saving model ...\nEpoch 7 Loss 0.649 Val Acc 76.660\n==> Saving model ...\nEpoch 8 Loss 0.595 Val Acc 77.160\n==> Saving model ...\nEpoch 9 Loss 0.551 Val Acc 78.280\n==> Saving model ...\nEpoch 10 Loss 0.517 Val Acc 78.750\n==> Saving model ...\nEpoch 11 Loss 0.506 Val Acc 81.260\nEpoch 12 Loss 0.485 Val Acc 80.710\nEpoch 13 Loss 0.474 Val Acc 79.600\n==> Saving model ...\nEpoch 14 Loss 0.456 Val Acc 81.600\nEpoch 15 Loss 0.444 Val Acc 74.780\nEpoch 16 Loss 0.438 Val Acc 80.910\n==> Saving model ...\nEpoch 17 Loss 0.417 Val Acc 84.200\nEpoch 18 Loss 0.418 Val Acc 77.100\nEpoch 19 Loss 0.399 Val Acc 79.330\nEpoch 20 Loss 0.398 Val Acc 76.110\nEpoch 21 Loss 0.392 Val Acc 74.550\nEpoch 22 Loss 0.375 Val Acc 83.890\nEpoch 23 Loss 0.385 Val Acc 79.850\nEpoch 24 Loss 0.366 Val Acc 83.650\n==> Saving model ...\nEpoch 25 Loss 0.370 Val Acc 84.790\n==> Saving model ...\nEpoch 26 Loss 0.357 Val Acc 85.290\nEpoch 27 Loss 0.360 Val Acc 83.000\nEpoch 28 Loss 0.351 Val Acc 83.590\nEpoch 29 Loss 0.345 Val Acc 81.840\nEpoch 30 Loss 0.343 Val Acc 82.490\nEpoch 31 Loss 0.346 Val Acc 81.540\nEpoch 32 Loss 0.340 Val Acc 82.280\nEpoch 33 Loss 0.323 Val Acc 82.140\nEpoch 34 Loss 0.331 Val Acc 79.320\n==> Saving model ...\nEpoch 35 Loss 0.335 Val Acc 86.470\nEpoch 36 Loss 0.317 Val Acc 77.570\nEpoch 37 Loss 0.319 Val Acc 83.150\nEpoch 38 Loss 0.322 Val Acc 85.500\nEpoch 39 Loss 0.312 Val Acc 80.940\nEpoch 40 Loss 0.310 Val Acc 84.010\nEpoch 41 Loss 0.319 Val Acc 84.700\nEpoch 42 Loss 0.308 Val Acc 82.920\nEpoch 43 Loss 0.311 Val Acc 85.050\nEpoch 44 Loss 0.298 Val Acc 84.290\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = ResNet18.to(device)\ncheckpoint = torch.load(checkpoint_dir / f\"baseline_max_acc_{VERSION}.pth\", map_location=device)\nmodel.load_state_dict(checkpoint['net'])\nmodel.eval()\nprint(f'Final test accuracy is: {calculate_accuracy(model, test_dataloader, device)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_stats_dir = Path('/kaggle/working/training_stats/')\nwith open(training_stats_dir / 'baseline_stats.pkl', 'wb') as file:\n    pickle.dump(stats)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}