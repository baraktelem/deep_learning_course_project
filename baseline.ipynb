{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081d835d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:19.548680Z",
     "iopub.status.busy": "2025-12-26T15:04:19.548443Z",
     "iopub.status.idle": "2025-12-26T15:04:34.079413Z",
     "shell.execute_reply": "2025-12-26T15:04:34.078761Z"
    },
    "executionInfo": {
     "elapsed": 5636,
     "status": "ok",
     "timestamp": 1766743875913,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "zNf1AQxVkZdi",
    "outputId": "7fd9b195-abbc-4da1-f986-982016920821",
    "papermill": {
     "duration": 14.536546,
     "end_time": "2025-12-26T15:04:34.081250",
     "exception": false,
     "start_time": "2025-12-26T15:04:19.544704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.2)\r\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.10)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->kornia) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->kornia) (3.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "!pip install kornia\n",
    "from kornia import augmentation as K\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "DEBUG = False\n",
    "VERSION = 0.1\n",
    "env = 'kaggle' # 'kaggle' or 'colab'\n",
    "\n",
    "if env == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = Path('/content/drive/MyDrive/dl_pj')    \n",
    "elif env == 'kaggle':\n",
    "    base_dir = Path('/kaggle/working/')\n",
    "\n",
    "checkpoint_dir = base_dir / 'checkpoints'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "training_stats_dir = base_dir / 'stats'\n",
    "training_stats_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a5db4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:34.087500Z",
     "iopub.status.busy": "2025-12-26T15:04:34.087131Z",
     "iopub.status.idle": "2025-12-26T15:04:34.097864Z",
     "shell.execute_reply": "2025-12-26T15:04:34.097156Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766743054230,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "ElgGUpWbrrci",
    "papermill": {
     "duration": 0.015524,
     "end_time": "2025-12-26T15:04:34.099261",
     "exception": false,
     "start_time": "2025-12-26T15:04:34.083737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layer = []\n",
    "        for s in strides:\n",
    "            layer.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7da7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:34.104409Z",
     "iopub.status.busy": "2025-12-26T15:04:34.104181Z",
     "iopub.status.idle": "2025-12-26T15:04:34.200362Z",
     "shell.execute_reply": "2025-12-26T15:04:34.199402Z"
    },
    "papermill": {
     "duration": 0.100399,
     "end_time": "2025-12-26T15:04:34.201821",
     "exception": false,
     "start_time": "2025-12-26T15:04:34.101422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 11,173,962\n",
      "Model Size: 42.63 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_summary(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    total_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    size_mb = total_bytes / (1024 ** 2)\n",
    "    return num_params, size_mb\n",
    "\n",
    "total_params, model_size_mb = get_model_summary(ResNet18())\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81b5450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:34.207335Z",
     "iopub.status.busy": "2025-12-26T15:04:34.207088Z",
     "iopub.status.idle": "2025-12-26T15:04:34.211749Z",
     "shell.execute_reply": "2025-12-26T15:04:34.211083Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1766743013043,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "k3Z55XXW407W",
    "papermill": {
     "duration": 0.009073,
     "end_time": "2025-12-26T15:04:34.213190",
     "exception": false,
     "start_time": "2025-12-26T15:04:34.204117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval() # put in evaluation mode,  turn off Dropout, BatchNorm uses learned statistics\n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = normalize(images)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    return model_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f20dbd",
   "metadata": {
    "id": "kJ7YrZBl6lho",
    "papermill": {
     "duration": 0.002076,
     "end_time": "2025-12-26T15:04:34.217325",
     "exception": false,
     "start_time": "2025-12-26T15:04:34.215249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split data set into train-validation-test.\n",
    "We are using 80% train, 20% validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8fb9d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:34.222499Z",
     "iopub.status.busy": "2025-12-26T15:04:34.222082Z",
     "iopub.status.idle": "2025-12-26T15:04:48.779625Z",
     "shell.execute_reply": "2025-12-26T15:04:48.779037Z"
    },
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1766743016313,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "rkI3-MRt58hj",
    "papermill": {
     "duration": 14.561988,
     "end_time": "2025-12-26T15:04:48.781327",
     "exception": false,
     "start_time": "2025-12-26T15:04:34.219339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:10<00:00, 16.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "# 80/20% split\n",
    "train_val_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(train_val_set))\n",
    "val_size = len(train_val_set) - train_size\n",
    "trainset, valset = random_split(\n",
    "    train_val_set,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564219b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:48.791913Z",
     "iopub.status.busy": "2025-12-26T15:04:48.791286Z",
     "iopub.status.idle": "2025-12-26T15:04:48.795701Z",
     "shell.execute_reply": "2025-12-26T15:04:48.794915Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1766743919319,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "Zy87RRrf7Vh6",
    "papermill": {
     "duration": 0.010938,
     "end_time": "2025-12-26T15:04:48.797066",
     "exception": false,
     "start_time": "2025-12-26T15:04:48.786128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "T_max = 200\n",
    "\n",
    "n_epochs = 1 if DEBUG else 200\n",
    "\n",
    "print_progress_every = 1\n",
    "val_accuracy_storing_threshold = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad96dad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:04:48.806918Z",
     "iopub.status.busy": "2025-12-26T15:04:48.806652Z",
     "iopub.status.idle": "2025-12-26T16:46:32.893664Z",
     "shell.execute_reply": "2025-12-26T16:46:32.892843Z"
    },
    "id": "W45Vot2zvrLE",
    "papermill": {
     "duration": 6104.105369,
     "end_time": "2025-12-26T16:46:32.906726",
     "exception": false,
     "start_time": "2025-12-26T15:04:48.801357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 1.918 Val Acc 37.560\n",
      "==> Saving model ...\n",
      "Epoch 1 Loss 1.459 Val Acc 50.730\n",
      "==> Saving model ...\n",
      "Epoch 2 Loss 1.234 Val Acc 60.270\n",
      "==> Saving model ...\n",
      "Epoch 3 Loss 1.037 Val Acc 64.860\n",
      "==> Saving model ...\n",
      "Epoch 4 Loss 0.890 Val Acc 71.540\n",
      "==> Saving model ...\n",
      "Epoch 5 Loss 0.760 Val Acc 73.440\n",
      "==> Saving model ...\n",
      "Epoch 6 Loss 0.680 Val Acc 75.730\n",
      "Epoch 7 Loss 0.631 Val Acc 72.090\n",
      "Epoch 8 Loss 0.580 Val Acc 73.730\n",
      "Epoch 9 Loss 0.549 Val Acc 74.420\n",
      "==> Saving model ...\n",
      "Epoch 10 Loss 0.529 Val Acc 77.370\n",
      "==> Saving model ...\n",
      "Epoch 11 Loss 0.508 Val Acc 79.750\n",
      "==> Saving model ...\n",
      "Epoch 12 Loss 0.493 Val Acc 81.630\n",
      "Epoch 13 Loss 0.466 Val Acc 76.910\n",
      "==> Saving model ...\n",
      "Epoch 14 Loss 0.454 Val Acc 82.110\n",
      "==> Saving model ...\n",
      "Epoch 15 Loss 0.449 Val Acc 82.320\n",
      "Epoch 16 Loss 0.434 Val Acc 80.040\n",
      "==> Saving model ...\n",
      "Epoch 17 Loss 0.423 Val Acc 83.160\n",
      "Epoch 18 Loss 0.413 Val Acc 80.390\n",
      "Epoch 19 Loss 0.412 Val Acc 83.130\n",
      "Epoch 20 Loss 0.401 Val Acc 79.300\n",
      "Epoch 21 Loss 0.389 Val Acc 82.260\n",
      "Epoch 22 Loss 0.387 Val Acc 80.770\n",
      "==> Saving model ...\n",
      "Epoch 23 Loss 0.381 Val Acc 84.160\n",
      "Epoch 24 Loss 0.375 Val Acc 81.840\n",
      "Epoch 25 Loss 0.376 Val Acc 79.470\n",
      "Epoch 26 Loss 0.373 Val Acc 83.470\n",
      "==> Saving model ...\n",
      "Epoch 27 Loss 0.363 Val Acc 85.660\n",
      "Epoch 28 Loss 0.345 Val Acc 83.010\n",
      "Epoch 29 Loss 0.365 Val Acc 83.580\n",
      "Epoch 30 Loss 0.352 Val Acc 83.400\n",
      "Epoch 31 Loss 0.340 Val Acc 80.240\n",
      "Epoch 32 Loss 0.345 Val Acc 83.470\n",
      "==> Saving model ...\n",
      "Epoch 33 Loss 0.330 Val Acc 86.500\n",
      "Epoch 34 Loss 0.333 Val Acc 80.400\n",
      "Epoch 35 Loss 0.345 Val Acc 80.210\n",
      "Epoch 36 Loss 0.322 Val Acc 84.210\n",
      "Epoch 37 Loss 0.325 Val Acc 83.180\n",
      "Epoch 38 Loss 0.333 Val Acc 84.760\n",
      "Epoch 39 Loss 0.316 Val Acc 84.170\n",
      "Epoch 40 Loss 0.309 Val Acc 79.800\n",
      "Epoch 41 Loss 0.323 Val Acc 85.300\n",
      "Epoch 42 Loss 0.315 Val Acc 83.900\n",
      "==> Saving model ...\n",
      "Epoch 43 Loss 0.316 Val Acc 86.760\n",
      "Epoch 44 Loss 0.294 Val Acc 82.200\n",
      "Epoch 45 Loss 0.306 Val Acc 84.690\n",
      "Epoch 46 Loss 0.307 Val Acc 84.380\n",
      "Epoch 47 Loss 0.289 Val Acc 85.550\n",
      "Epoch 48 Loss 0.299 Val Acc 75.530\n",
      "Epoch 49 Loss 0.297 Val Acc 80.440\n",
      "Epoch 50 Loss 0.285 Val Acc 85.390\n",
      "Epoch 51 Loss 0.285 Val Acc 85.580\n",
      "Epoch 52 Loss 0.287 Val Acc 86.210\n",
      "Epoch 53 Loss 0.293 Val Acc 83.670\n",
      "Epoch 54 Loss 0.278 Val Acc 83.880\n",
      "==> Saving model ...\n",
      "Epoch 55 Loss 0.288 Val Acc 86.880\n",
      "Epoch 56 Loss 0.281 Val Acc 85.300\n",
      "Epoch 57 Loss 0.280 Val Acc 83.750\n",
      "Epoch 58 Loss 0.272 Val Acc 85.720\n",
      "Epoch 59 Loss 0.271 Val Acc 86.570\n",
      "Epoch 60 Loss 0.267 Val Acc 84.290\n",
      "Epoch 61 Loss 0.265 Val Acc 85.220\n",
      "Epoch 62 Loss 0.257 Val Acc 84.920\n",
      "Epoch 63 Loss 0.263 Val Acc 80.910\n",
      "Epoch 64 Loss 0.269 Val Acc 86.520\n",
      "Epoch 65 Loss 0.252 Val Acc 86.620\n",
      "Epoch 66 Loss 0.254 Val Acc 86.780\n",
      "Epoch 67 Loss 0.262 Val Acc 85.800\n",
      "Epoch 68 Loss 0.248 Val Acc 85.240\n",
      "Epoch 69 Loss 0.258 Val Acc 85.490\n",
      "Epoch 70 Loss 0.251 Val Acc 85.500\n",
      "Epoch 71 Loss 0.244 Val Acc 82.830\n",
      "Epoch 72 Loss 0.234 Val Acc 85.500\n",
      "==> Saving model ...\n",
      "Epoch 73 Loss 0.244 Val Acc 87.250\n",
      "Epoch 74 Loss 0.233 Val Acc 87.040\n",
      "Epoch 75 Loss 0.246 Val Acc 86.520\n",
      "Epoch 76 Loss 0.233 Val Acc 85.830\n",
      "Epoch 77 Loss 0.235 Val Acc 85.240\n",
      "Epoch 78 Loss 0.225 Val Acc 84.530\n",
      "==> Saving model ...\n",
      "Epoch 79 Loss 0.226 Val Acc 87.290\n",
      "Epoch 80 Loss 0.215 Val Acc 86.330\n",
      "==> Saving model ...\n",
      "Epoch 81 Loss 0.230 Val Acc 87.970\n",
      "Epoch 82 Loss 0.210 Val Acc 84.150\n",
      "Epoch 83 Loss 0.220 Val Acc 84.250\n",
      "Epoch 84 Loss 0.218 Val Acc 86.820\n",
      "Epoch 85 Loss 0.207 Val Acc 86.470\n",
      "Epoch 86 Loss 0.213 Val Acc 84.900\n",
      "Epoch 87 Loss 0.203 Val Acc 87.310\n",
      "Epoch 88 Loss 0.205 Val Acc 85.680\n",
      "Epoch 89 Loss 0.208 Val Acc 84.270\n",
      "Epoch 90 Loss 0.205 Val Acc 87.350\n",
      "==> Saving model ...\n",
      "Epoch 91 Loss 0.199 Val Acc 88.370\n",
      "Epoch 92 Loss 0.195 Val Acc 82.720\n",
      "==> Saving model ...\n",
      "Epoch 93 Loss 0.181 Val Acc 89.530\n",
      "Epoch 94 Loss 0.188 Val Acc 88.430\n",
      "Epoch 95 Loss 0.178 Val Acc 86.960\n",
      "Epoch 96 Loss 0.183 Val Acc 88.760\n",
      "Epoch 97 Loss 0.178 Val Acc 89.090\n",
      "Epoch 98 Loss 0.179 Val Acc 88.890\n",
      "Epoch 99 Loss 0.169 Val Acc 87.250\n",
      "Epoch 100 Loss 0.186 Val Acc 87.870\n",
      "Epoch 101 Loss 0.163 Val Acc 89.440\n",
      "Epoch 102 Loss 0.154 Val Acc 89.460\n",
      "Epoch 103 Loss 0.159 Val Acc 87.940\n",
      "Epoch 104 Loss 0.161 Val Acc 88.600\n",
      "Epoch 105 Loss 0.159 Val Acc 88.470\n",
      "Epoch 106 Loss 0.155 Val Acc 89.170\n",
      "Epoch 107 Loss 0.157 Val Acc 88.560\n",
      "Epoch 108 Loss 0.151 Val Acc 87.710\n",
      "Epoch 109 Loss 0.145 Val Acc 89.330\n",
      "Epoch 110 Loss 0.144 Val Acc 89.380\n",
      "Epoch 111 Loss 0.147 Val Acc 89.380\n",
      "Epoch 112 Loss 0.145 Val Acc 86.540\n",
      "==> Saving model ...\n",
      "Epoch 113 Loss 0.145 Val Acc 90.420\n",
      "Epoch 114 Loss 0.139 Val Acc 87.690\n",
      "Epoch 115 Loss 0.132 Val Acc 89.270\n",
      "Epoch 116 Loss 0.136 Val Acc 89.490\n",
      "Epoch 117 Loss 0.125 Val Acc 90.120\n",
      "Epoch 118 Loss 0.129 Val Acc 88.430\n",
      "Epoch 119 Loss 0.122 Val Acc 88.520\n",
      "Epoch 120 Loss 0.124 Val Acc 88.520\n",
      "Epoch 121 Loss 0.119 Val Acc 89.290\n",
      "Epoch 122 Loss 0.112 Val Acc 90.340\n",
      "Epoch 123 Loss 0.106 Val Acc 89.490\n",
      "Epoch 124 Loss 0.114 Val Acc 89.690\n",
      "Epoch 125 Loss 0.106 Val Acc 89.380\n",
      "Epoch 126 Loss 0.102 Val Acc 89.180\n",
      "Epoch 127 Loss 0.100 Val Acc 89.810\n",
      "==> Saving model ...\n",
      "Epoch 128 Loss 0.090 Val Acc 90.780\n",
      "Epoch 129 Loss 0.108 Val Acc 89.280\n",
      "==> Saving model ...\n",
      "Epoch 130 Loss 0.094 Val Acc 91.200\n",
      "Epoch 131 Loss 0.095 Val Acc 90.600\n",
      "Epoch 132 Loss 0.091 Val Acc 90.870\n",
      "Epoch 133 Loss 0.086 Val Acc 90.560\n",
      "==> Saving model ...\n",
      "Epoch 134 Loss 0.084 Val Acc 91.500\n",
      "Epoch 135 Loss 0.076 Val Acc 89.960\n",
      "==> Saving model ...\n",
      "Epoch 136 Loss 0.077 Val Acc 91.880\n",
      "Epoch 137 Loss 0.069 Val Acc 90.110\n",
      "Epoch 138 Loss 0.074 Val Acc 90.080\n",
      "Epoch 139 Loss 0.067 Val Acc 91.270\n",
      "Epoch 140 Loss 0.074 Val Acc 88.980\n",
      "Epoch 141 Loss 0.065 Val Acc 91.200\n",
      "==> Saving model ...\n",
      "Epoch 142 Loss 0.064 Val Acc 92.330\n",
      "Epoch 143 Loss 0.065 Val Acc 90.780\n",
      "Epoch 144 Loss 0.054 Val Acc 90.990\n",
      "Epoch 145 Loss 0.052 Val Acc 90.390\n",
      "Epoch 146 Loss 0.042 Val Acc 91.250\n",
      "Epoch 147 Loss 0.047 Val Acc 92.000\n",
      "Epoch 148 Loss 0.043 Val Acc 91.600\n",
      "Epoch 149 Loss 0.048 Val Acc 92.170\n",
      "Epoch 150 Loss 0.043 Val Acc 91.550\n",
      "==> Saving model ...\n",
      "Epoch 151 Loss 0.039 Val Acc 92.870\n",
      "==> Saving model ...\n",
      "Epoch 152 Loss 0.043 Val Acc 93.010\n",
      "Epoch 153 Loss 0.042 Val Acc 91.730\n",
      "==> Saving model ...\n",
      "Epoch 154 Loss 0.034 Val Acc 93.090\n",
      "Epoch 155 Loss 0.027 Val Acc 92.610\n",
      "Epoch 156 Loss 0.033 Val Acc 92.660\n",
      "Epoch 157 Loss 0.029 Val Acc 91.520\n",
      "Epoch 158 Loss 0.029 Val Acc 92.300\n",
      "==> Saving model ...\n",
      "Epoch 159 Loss 0.023 Val Acc 93.240\n",
      "Epoch 160 Loss 0.022 Val Acc 90.780\n",
      "Epoch 161 Loss 0.020 Val Acc 92.990\n",
      "==> Saving model ...\n",
      "Epoch 162 Loss 0.019 Val Acc 93.350\n",
      "==> Saving model ...\n",
      "Epoch 163 Loss 0.018 Val Acc 93.670\n",
      "Epoch 164 Loss 0.017 Val Acc 93.430\n",
      "Epoch 165 Loss 0.017 Val Acc 93.490\n",
      "==> Saving model ...\n",
      "Epoch 166 Loss 0.017 Val Acc 93.740\n",
      "==> Saving model ...\n",
      "Epoch 167 Loss 0.012 Val Acc 94.280\n",
      "Epoch 168 Loss 0.014 Val Acc 93.500\n",
      "Epoch 169 Loss 0.012 Val Acc 93.840\n",
      "==> Saving model ...\n",
      "Epoch 170 Loss 0.011 Val Acc 94.370\n",
      "Epoch 171 Loss 0.009 Val Acc 94.180\n",
      "Epoch 172 Loss 0.009 Val Acc 94.300\n",
      "Epoch 173 Loss 0.009 Val Acc 93.590\n",
      "Epoch 174 Loss 0.007 Val Acc 93.800\n",
      "Epoch 175 Loss 0.007 Val Acc 94.210\n",
      "Epoch 176 Loss 0.008 Val Acc 94.280\n",
      "==> Saving model ...\n",
      "Epoch 177 Loss 0.006 Val Acc 94.440\n",
      "Epoch 178 Loss 0.006 Val Acc 94.010\n",
      "Epoch 179 Loss 0.007 Val Acc 93.810\n",
      "==> Saving model ...\n",
      "Epoch 180 Loss 0.006 Val Acc 94.530\n",
      "==> Saving model ...\n",
      "Epoch 181 Loss 0.006 Val Acc 94.620\n",
      "Epoch 182 Loss 0.005 Val Acc 94.580\n",
      "Epoch 183 Loss 0.005 Val Acc 94.510\n",
      "Epoch 184 Loss 0.006 Val Acc 94.030\n",
      "==> Saving model ...\n",
      "Epoch 185 Loss 0.005 Val Acc 94.660\n",
      "Epoch 186 Loss 0.005 Val Acc 94.460\n",
      "Epoch 187 Loss 0.005 Val Acc 94.480\n",
      "Epoch 188 Loss 0.006 Val Acc 94.600\n",
      "==> Saving model ...\n",
      "Epoch 189 Loss 0.004 Val Acc 94.720\n",
      "==> Saving model ...\n",
      "Epoch 190 Loss 0.004 Val Acc 94.760\n",
      "Epoch 191 Loss 0.004 Val Acc 94.750\n",
      "Epoch 192 Loss 0.004 Val Acc 94.710\n",
      "Epoch 193 Loss 0.005 Val Acc 94.690\n",
      "==> Saving model ...\n",
      "Epoch 194 Loss 0.004 Val Acc 94.810\n",
      "==> Saving model ...\n",
      "Epoch 195 Loss 0.004 Val Acc 94.840\n",
      "Epoch 196 Loss 0.005 Val Acc 94.560\n",
      "Epoch 197 Loss 0.004 Val Acc 94.580\n",
      "Epoch 198 Loss 0.005 Val Acc 94.820\n",
      "==> Saving model ...\n",
      "Epoch 199 Loss 0.004 Val Acc 94.890\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465]).to(device)\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010]).to(device)\n",
    "normalize = K.Normalize(mean=mean, std=std)\n",
    "# define a sequence of augmentations\n",
    "aug_list = AugmentationSequential(\n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.2),\n",
    "    K.RandomResizedCrop(size=(32,32), scale=(0.7, 1.0), p=0.5),\n",
    "    normalize,\n",
    "    same_on_batch=False\n",
    ").to(device)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "model = ResNet18().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "\n",
    "stats = {\n",
    "    'total_training_time': 0,\n",
    "    'loss': [],\n",
    "    'time_per_epoch': [],\n",
    "    'total_time_per_epoch': [],\n",
    "    'val_accuracy': [],\n",
    "    'max_val_accuracy': 0,\n",
    "    'allocated_memory': [], # Memory currently used by Tensors\n",
    "    'reserved_memory': [], # Memory held by the PyTorch caching allocator\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    iteration_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        inputs = aug_list(inputs)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration_losses.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_end_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    val_accuracy = calculate_accuracy(model, valloader, device)\n",
    "\n",
    "    # Track stats\n",
    "    if (epoch % 1) == 0:\n",
    "        stats['loss'].append(\n",
    "            np.mean(iteration_losses)\n",
    "        )\n",
    "        stats['val_accuracy'].append(\n",
    "            val_accuracy\n",
    "        )\n",
    "        stats['allocated_memory'].append(torch.cuda.memory_allocated())\n",
    "        stats['reserved_memory'].append(torch.cuda.memory_reserved())\n",
    "        stats['time_per_epoch'].append(epoch_end_time - epoch_start_time)\n",
    "        stats['total_time_per_epoch'].append(time.time() - start_time)\n",
    "\n",
    "    # Store best model\n",
    "    if (val_accuracy > stats['max_val_accuracy']):\n",
    "        if (val_accuracy > val_accuracy_storing_threshold):\n",
    "            stats['max_val_accuracy'] = val_accuracy\n",
    "            print('==> Saving model ...')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'acc':val_accuracy\n",
    "            }\n",
    "            save_path = checkpoint_dir / f\"baseline_max_acc_{VERSION}.pth\"\n",
    "            torch.save(state, save_path)\n",
    "\n",
    "    if DEBUG:\n",
    "        print('==> Saving model ... DEBUG')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'acc':val_accuracy\n",
    "        }\n",
    "        save_path = checkpoint_dir / f\"baseline_max_acc_{VERSION}.pth\"\n",
    "        torch.save(state, save_path)\n",
    "        \n",
    "    # Print progress\n",
    "    if (epoch % print_progress_every) == 0:\n",
    "        print(f\"Epoch {epoch} Loss {stats['loss'][-1]:.3f} Val Acc {stats['val_accuracy'][-1]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f5c28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:46:32.931681Z",
     "iopub.status.busy": "2025-12-26T16:46:32.931407Z",
     "iopub.status.idle": "2025-12-26T16:46:35.908929Z",
     "shell.execute_reply": "2025-12-26T16:46:35.908052Z"
    },
    "papermill": {
     "duration": 2.991834,
     "end_time": "2025-12-26T16:46:35.910397",
     "exception": false,
     "start_time": "2025-12-26T16:46:32.918563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy is: 94.140\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18().to(device)\n",
    "checkpoint = torch.load(checkpoint_dir / f\"baseline_max_acc_{VERSION}.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "print(f'Final test accuracy is: {calculate_accuracy(model, testloader, device):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebfcac6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:46:35.934111Z",
     "iopub.status.busy": "2025-12-26T16:46:35.933878Z",
     "iopub.status.idle": "2025-12-26T16:46:35.938545Z",
     "shell.execute_reply": "2025-12-26T16:46:35.937830Z"
    },
    "papermill": {
     "duration": 0.01795,
     "end_time": "2025-12-26T16:46:35.940004",
     "exception": false,
     "start_time": "2025-12-26T16:46:35.922054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(training_stats_dir / 'baseline_stats.pkl', 'wb') as file:\n",
    "    pickle.dump(stats, file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlKRvREyFsuJ9trrs14c5Y",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6141.248172,
   "end_time": "2025-12-26T16:46:38.389277",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-26T15:04:17.141105",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
