{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e87acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:27.249047Z",
     "iopub.status.busy": "2026-01-06T17:30:27.248739Z",
     "iopub.status.idle": "2026-01-06T17:30:47.805201Z",
     "shell.execute_reply": "2026-01-06T17:30:47.804324Z"
    },
    "executionInfo": {
     "elapsed": 5636,
     "status": "ok",
     "timestamp": 1766743875913,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "zNf1AQxVkZdi",
    "outputId": "7fd9b195-abbc-4da1-f986-982016920821",
    "papermill": {
     "duration": 20.562565,
     "end_time": "2026-01-06T17:30:47.807137",
     "exception": false,
     "start_time": "2026-01-06T17:30:27.244572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.2)\r\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.10)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->kornia) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->kornia) (3.0.3)\r\n",
      "Collecting kymatio\r\n",
      "  Downloading kymatio-0.3.0-py3-none-any.whl.metadata (9.6 kB)\r\n",
      "Collecting appdirs (from kymatio)\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting configparser (from kymatio)\r\n",
      "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from kymatio) (2.0.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kymatio) (25.0)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from kymatio) (1.15.3)\r\n",
      "Downloading kymatio-0.3.0-py3-none-any.whl (87 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\r\n",
      "Installing collected packages: appdirs, configparser, kymatio\r\n",
      "Successfully installed appdirs-1.4.4 configparser-7.2.0 kymatio-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "!pip install kornia\n",
    "!pip install kymatio\n",
    "from kornia import augmentation as K\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from kymatio.torch import Scattering2D\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "DEBUG = False\n",
    "MODEL_NAME = \"ScatResNet18_biomass\"\n",
    "env = 'kaggle' # 'kaggle' or 'colab'\n",
    "\n",
    "if env == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = Path('/content/drive/MyDrive/dl_pj')    \n",
    "elif env == 'kaggle':\n",
    "    base_dir = Path('/kaggle/working/')\n",
    "\n",
    "checkpoint_dir = base_dir / 'checkpoints'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "training_stats_dir = base_dir / 'stats'\n",
    "training_stats_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350633d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:47.814189Z",
     "iopub.status.busy": "2026-01-06T17:30:47.813755Z",
     "iopub.status.idle": "2026-01-06T17:30:47.825837Z",
     "shell.execute_reply": "2026-01-06T17:30:47.825122Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766743054230,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "ElgGUpWbrrci",
    "papermill": {
     "duration": 0.017254,
     "end_time": "2026-01-06T17:30:47.827238",
     "exception": false,
     "start_time": "2026-01-06T17:30:47.809984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, L=8):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.L = L\n",
    "        \n",
    "        self.scat_channels = (1 + L) * 3\n",
    "        self.scat1 = Scattering2D(J=1, shape=(224, 224), L=L, max_order=2, backend='torch')        \n",
    "        self.conv1 = nn.Conv2d(3, 64 - self.scat_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layer = []\n",
    "        for s in strides:\n",
    "            layer.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        out_conv = self.conv1(x)\n",
    "        out_scat = self.scat1(x)\n",
    "        out_scat = out_scat.view(out_scat.size(0), -1, 112, 112)\n",
    "        out = torch.cat([out_conv, out_scat], dim=1)\n",
    "        out = self.maxpool1(F.relu(self.bn1(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = F.adaptive_avg_pool2d(out, (1,1))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ScatResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4acb958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:47.833098Z",
     "iopub.status.busy": "2026-01-06T17:30:47.832853Z",
     "iopub.status.idle": "2026-01-06T17:30:49.427586Z",
     "shell.execute_reply": "2026-01-06T17:30:49.426627Z"
    },
    "papermill": {
     "duration": 1.599464,
     "end_time": "2026-01-06T17:30:49.429139",
     "exception": false,
     "start_time": "2026-01-06T17:30:47.829675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 11,175,108\n",
      "Model Size: 42.63 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_summary(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    total_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    size_mb = total_bytes / (1024 ** 2)\n",
    "    return num_params, size_mb\n",
    "\n",
    "total_params, model_size_mb = get_model_summary(ScatResNet18())\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3119a1d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:49.435555Z",
     "iopub.status.busy": "2026-01-06T17:30:49.435292Z",
     "iopub.status.idle": "2026-01-06T17:30:49.440814Z",
     "shell.execute_reply": "2026-01-06T17:30:49.440140Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1766743013043,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "k3Z55XXW407W",
    "papermill": {
     "duration": 0.010227,
     "end_time": "2026-01-06T17:30:49.442140",
     "exception": false,
     "start_time": "2026-01-06T17:30:49.431913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_mse(model, dataloader, device):\n",
    "    model.eval() \n",
    "    total_mse = 0\n",
    "    total_samples = 0\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            total_samples += targets.size(0)\n",
    "            total_mse += criterion(outputs, targets).item()\n",
    "\n",
    "    \n",
    "    return total_mse / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee07035b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:49.448236Z",
     "iopub.status.busy": "2026-01-06T17:30:49.447998Z",
     "iopub.status.idle": "2026-01-06T17:30:49.454716Z",
     "shell.execute_reply": "2026-01-06T17:30:49.454146Z"
    },
    "papermill": {
     "duration": 0.011378,
     "end_time": "2026-01-06T17:30:49.456038",
     "exception": false,
     "start_time": "2026-01-06T17:30:49.444660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGETS_FACTOR = 1/2000\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, test_mode=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.test_mode = test_mode\n",
    "        if not self.test_mode:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df[['image_id', 'tmp']] = df['sample_id'].str.split(\"__\", expand=True)\n",
    "            self.data = df.pivot(index='image_id', columns='target_name', values='target')\n",
    "            self.target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "            self.data = self.data[self.target_cols].reset_index()\n",
    "            self.image_ids = self.data['image_id'].values\n",
    "            self.targets = self.data[self.target_cols].values.astype('float32') * TARGETS_FACTOR\n",
    "        else:\n",
    "            self.image_ids = [f.split('.')[0] for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id  = self.image_ids[idx]\n",
    "    \n",
    "        image_name = os.path.join(self.img_dir, f\"{image_id}.jpg\")\n",
    "    \n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return image, image_id\n",
    "    \n",
    "        target = torch.tensor(self.targets[idx])\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655c812a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:49.462050Z",
     "iopub.status.busy": "2026-01-06T17:30:49.461782Z",
     "iopub.status.idle": "2026-01-06T17:30:49.529774Z",
     "shell.execute_reply": "2026-01-06T17:30:49.529021Z"
    },
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1766743016313,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "rkI3-MRt58hj",
    "papermill": {
     "duration": 0.072878,
     "end_time": "2026-01-06T17:30:49.531444",
     "exception": false,
     "start_time": "2026-01-06T17:30:49.458566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010])\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomCrop((448,448)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.CenterCrop((448,448)),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset_full = BiomassDataset(\n",
    "    csv_file='/kaggle/input/csiro-biomass/train.csv',\n",
    "    img_dir='/kaggle/input/csiro-biomass/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset_full = BiomassDataset(\n",
    "    csv_file='/kaggle/input/csiro-biomass/train.csv',\n",
    "    img_dir='/kaggle/input/csiro-biomass/train',\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "dataset_size = len(train_dataset_full)\n",
    "train_len = int(0.8 * dataset_size)\n",
    "val_len = dataset_size - train_len\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_subset_tmp, val_subset_tmp = random_split(\n",
    "    train_dataset_full, [train_len, val_len], generator=generator\n",
    ")\n",
    "train_idx = train_subset_tmp.indices\n",
    "val_idx = val_subset_tmp.indices\n",
    "\n",
    "trainset = Subset(train_dataset_full, train_idx)\n",
    "valset = Subset(val_dataset_full, val_idx)\n",
    "\n",
    "testset = BiomassDataset(\n",
    "    csv_file='/kaggle/input/csiro-biomass/test.csv',\n",
    "    img_dir='/kaggle/input/csiro-biomass/test',\n",
    "    transform=val_transform,\n",
    "    test_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843f05ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:49.538520Z",
     "iopub.status.busy": "2026-01-06T17:30:49.538091Z",
     "iopub.status.idle": "2026-01-06T17:30:49.541897Z",
     "shell.execute_reply": "2026-01-06T17:30:49.541218Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1766743919319,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "Zy87RRrf7Vh6",
    "papermill": {
     "duration": 0.008912,
     "end_time": "2026-01-06T17:30:49.543326",
     "exception": false,
     "start_time": "2026-01-06T17:30:49.534414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "batch_size = 32\n",
    "\n",
    "lr = 1e-4\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "T_max = 200\n",
    "\n",
    "n_epochs = 1 if DEBUG else 200\n",
    "\n",
    "print_progress_every = 1\n",
    "val_mse_storing_threshold = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a093e5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:30:49.549550Z",
     "iopub.status.busy": "2026-01-06T17:30:49.549306Z",
     "iopub.status.idle": "2026-01-06T18:02:34.983303Z",
     "shell.execute_reply": "2026-01-06T18:02:34.982187Z"
    },
    "id": "W45Vot2zvrLE",
    "papermill": {
     "duration": 1905.43931,
     "end_time": "2026-01-06T18:02:34.985109",
     "exception": false,
     "start_time": "2026-01-06T17:30:49.545799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving model ...\n",
      "Epoch 0 Train loss 0.193 Val mse 0.180\n",
      "Epoch 1 Train loss 0.041 Val mse 0.213\n",
      "==> Saving model ...\n",
      "Epoch 2 Train loss 0.014 Val mse 0.069\n",
      "==> Saving model ...\n",
      "Epoch 3 Train loss 0.016 Val mse 0.024\n",
      "==> Saving model ...\n",
      "Epoch 4 Train loss 0.009 Val mse 0.020\n",
      "Epoch 5 Train loss 0.008 Val mse 0.025\n",
      "Epoch 6 Train loss 0.007 Val mse 0.029\n",
      "Epoch 7 Train loss 0.007 Val mse 0.030\n",
      "Epoch 8 Train loss 0.007 Val mse 0.031\n",
      "Epoch 9 Train loss 0.006 Val mse 0.030\n",
      "Epoch 10 Train loss 0.007 Val mse 0.030\n",
      "Epoch 11 Train loss 0.006 Val mse 0.031\n",
      "Epoch 12 Train loss 0.007 Val mse 0.030\n",
      "Epoch 13 Train loss 0.006 Val mse 0.030\n",
      "Epoch 14 Train loss 0.006 Val mse 0.029\n",
      "Epoch 15 Train loss 0.006 Val mse 0.030\n",
      "Epoch 16 Train loss 0.006 Val mse 0.030\n",
      "Epoch 17 Train loss 0.006 Val mse 0.029\n",
      "Epoch 18 Train loss 0.006 Val mse 0.029\n",
      "Epoch 19 Train loss 0.006 Val mse 0.029\n",
      "Epoch 20 Train loss 0.006 Val mse 0.029\n",
      "Epoch 21 Train loss 0.007 Val mse 0.029\n",
      "Epoch 22 Train loss 0.006 Val mse 0.029\n",
      "Epoch 23 Train loss 0.006 Val mse 0.029\n",
      "Epoch 24 Train loss 0.006 Val mse 0.029\n",
      "Epoch 25 Train loss 0.006 Val mse 0.028\n",
      "Epoch 26 Train loss 0.006 Val mse 0.029\n",
      "Epoch 27 Train loss 0.006 Val mse 0.028\n",
      "Epoch 28 Train loss 0.006 Val mse 0.029\n",
      "Epoch 29 Train loss 0.006 Val mse 0.029\n",
      "Epoch 30 Train loss 0.006 Val mse 0.029\n",
      "Epoch 31 Train loss 0.006 Val mse 0.028\n",
      "Epoch 32 Train loss 0.006 Val mse 0.028\n",
      "Epoch 33 Train loss 0.006 Val mse 0.027\n",
      "Epoch 34 Train loss 0.006 Val mse 0.028\n",
      "Epoch 35 Train loss 0.006 Val mse 0.028\n",
      "Epoch 36 Train loss 0.006 Val mse 0.028\n",
      "Epoch 37 Train loss 0.006 Val mse 0.028\n",
      "Epoch 38 Train loss 0.006 Val mse 0.027\n",
      "Epoch 39 Train loss 0.006 Val mse 0.028\n",
      "Epoch 40 Train loss 0.006 Val mse 0.028\n",
      "Epoch 41 Train loss 0.006 Val mse 0.028\n",
      "Epoch 42 Train loss 0.006 Val mse 0.028\n",
      "Epoch 43 Train loss 0.006 Val mse 0.028\n",
      "Epoch 44 Train loss 0.006 Val mse 0.027\n",
      "Epoch 45 Train loss 0.006 Val mse 0.028\n",
      "Epoch 46 Train loss 0.006 Val mse 0.028\n",
      "Epoch 47 Train loss 0.006 Val mse 0.027\n",
      "Epoch 48 Train loss 0.006 Val mse 0.027\n",
      "Epoch 49 Train loss 0.006 Val mse 0.027\n",
      "Epoch 50 Train loss 0.006 Val mse 0.027\n",
      "Epoch 51 Train loss 0.006 Val mse 0.027\n",
      "Epoch 52 Train loss 0.006 Val mse 0.027\n",
      "Epoch 53 Train loss 0.006 Val mse 0.027\n",
      "Epoch 54 Train loss 0.005 Val mse 0.027\n",
      "Epoch 55 Train loss 0.006 Val mse 0.027\n",
      "Epoch 56 Train loss 0.006 Val mse 0.027\n",
      "Epoch 57 Train loss 0.006 Val mse 0.027\n",
      "Epoch 58 Train loss 0.006 Val mse 0.027\n",
      "Epoch 59 Train loss 0.005 Val mse 0.027\n",
      "Epoch 60 Train loss 0.005 Val mse 0.026\n",
      "Epoch 61 Train loss 0.006 Val mse 0.027\n",
      "Epoch 62 Train loss 0.006 Val mse 0.027\n",
      "Epoch 63 Train loss 0.006 Val mse 0.027\n",
      "Epoch 64 Train loss 0.005 Val mse 0.026\n",
      "Epoch 65 Train loss 0.006 Val mse 0.026\n",
      "Epoch 66 Train loss 0.005 Val mse 0.026\n",
      "Epoch 67 Train loss 0.005 Val mse 0.026\n",
      "Epoch 68 Train loss 0.005 Val mse 0.026\n",
      "Epoch 69 Train loss 0.005 Val mse 0.026\n",
      "Epoch 70 Train loss 0.006 Val mse 0.026\n",
      "Epoch 71 Train loss 0.006 Val mse 0.026\n",
      "Epoch 72 Train loss 0.005 Val mse 0.026\n",
      "Epoch 73 Train loss 0.005 Val mse 0.027\n",
      "Epoch 74 Train loss 0.005 Val mse 0.025\n",
      "Epoch 75 Train loss 0.005 Val mse 0.026\n",
      "Epoch 76 Train loss 0.006 Val mse 0.026\n",
      "Epoch 77 Train loss 0.005 Val mse 0.026\n",
      "Epoch 78 Train loss 0.005 Val mse 0.025\n",
      "Epoch 79 Train loss 0.006 Val mse 0.026\n",
      "Epoch 80 Train loss 0.006 Val mse 0.026\n",
      "Epoch 81 Train loss 0.006 Val mse 0.026\n",
      "Epoch 82 Train loss 0.006 Val mse 0.026\n",
      "Epoch 83 Train loss 0.006 Val mse 0.026\n",
      "Epoch 84 Train loss 0.005 Val mse 0.026\n",
      "Epoch 85 Train loss 0.006 Val mse 0.025\n",
      "Epoch 86 Train loss 0.006 Val mse 0.026\n",
      "Epoch 87 Train loss 0.005 Val mse 0.026\n",
      "Epoch 88 Train loss 0.005 Val mse 0.026\n",
      "Epoch 89 Train loss 0.006 Val mse 0.026\n",
      "Epoch 90 Train loss 0.005 Val mse 0.025\n",
      "Epoch 91 Train loss 0.006 Val mse 0.026\n",
      "Epoch 92 Train loss 0.005 Val mse 0.026\n",
      "Epoch 93 Train loss 0.006 Val mse 0.026\n",
      "Epoch 94 Train loss 0.006 Val mse 0.026\n",
      "Epoch 95 Train loss 0.005 Val mse 0.026\n",
      "Epoch 96 Train loss 0.005 Val mse 0.025\n",
      "Epoch 97 Train loss 0.005 Val mse 0.025\n",
      "Epoch 98 Train loss 0.006 Val mse 0.025\n",
      "Epoch 99 Train loss 0.006 Val mse 0.026\n",
      "Epoch 100 Train loss 0.005 Val mse 0.026\n",
      "Epoch 101 Train loss 0.006 Val mse 0.025\n",
      "Epoch 102 Train loss 0.005 Val mse 0.025\n",
      "Epoch 103 Train loss 0.005 Val mse 0.025\n",
      "Epoch 104 Train loss 0.005 Val mse 0.026\n",
      "Epoch 105 Train loss 0.005 Val mse 0.025\n",
      "Epoch 106 Train loss 0.005 Val mse 0.025\n",
      "Epoch 107 Train loss 0.005 Val mse 0.025\n",
      "Epoch 108 Train loss 0.005 Val mse 0.025\n",
      "Epoch 109 Train loss 0.005 Val mse 0.025\n",
      "Epoch 110 Train loss 0.006 Val mse 0.025\n",
      "Epoch 111 Train loss 0.005 Val mse 0.025\n",
      "Epoch 112 Train loss 0.005 Val mse 0.025\n",
      "Epoch 113 Train loss 0.005 Val mse 0.025\n",
      "Epoch 114 Train loss 0.005 Val mse 0.025\n",
      "Epoch 115 Train loss 0.005 Val mse 0.025\n",
      "Epoch 116 Train loss 0.005 Val mse 0.026\n",
      "Epoch 117 Train loss 0.006 Val mse 0.025\n",
      "Epoch 118 Train loss 0.005 Val mse 0.026\n",
      "Epoch 119 Train loss 0.005 Val mse 0.025\n",
      "Epoch 120 Train loss 0.005 Val mse 0.026\n",
      "Epoch 121 Train loss 0.005 Val mse 0.025\n",
      "Epoch 122 Train loss 0.006 Val mse 0.025\n",
      "Epoch 123 Train loss 0.005 Val mse 0.025\n",
      "Epoch 124 Train loss 0.005 Val mse 0.025\n",
      "Epoch 125 Train loss 0.006 Val mse 0.025\n",
      "Epoch 126 Train loss 0.006 Val mse 0.025\n",
      "Epoch 127 Train loss 0.006 Val mse 0.025\n",
      "Epoch 128 Train loss 0.006 Val mse 0.025\n",
      "Epoch 129 Train loss 0.005 Val mse 0.025\n",
      "Epoch 130 Train loss 0.005 Val mse 0.025\n",
      "Epoch 131 Train loss 0.005 Val mse 0.025\n",
      "Epoch 132 Train loss 0.005 Val mse 0.025\n",
      "Epoch 133 Train loss 0.005 Val mse 0.025\n",
      "Epoch 134 Train loss 0.006 Val mse 0.025\n",
      "Epoch 135 Train loss 0.005 Val mse 0.025\n",
      "Epoch 136 Train loss 0.006 Val mse 0.025\n",
      "Epoch 137 Train loss 0.005 Val mse 0.025\n",
      "Epoch 138 Train loss 0.005 Val mse 0.025\n",
      "Epoch 139 Train loss 0.005 Val mse 0.025\n",
      "Epoch 140 Train loss 0.005 Val mse 0.025\n",
      "Epoch 141 Train loss 0.006 Val mse 0.025\n",
      "Epoch 142 Train loss 0.005 Val mse 0.025\n",
      "Epoch 143 Train loss 0.005 Val mse 0.025\n",
      "Epoch 144 Train loss 0.005 Val mse 0.025\n",
      "Epoch 145 Train loss 0.005 Val mse 0.025\n",
      "Epoch 146 Train loss 0.005 Val mse 0.025\n",
      "Epoch 147 Train loss 0.005 Val mse 0.025\n",
      "Epoch 148 Train loss 0.006 Val mse 0.025\n",
      "Epoch 149 Train loss 0.006 Val mse 0.025\n",
      "Epoch 150 Train loss 0.005 Val mse 0.026\n",
      "Epoch 151 Train loss 0.005 Val mse 0.025\n",
      "Epoch 152 Train loss 0.005 Val mse 0.025\n",
      "Epoch 153 Train loss 0.006 Val mse 0.024\n",
      "Epoch 154 Train loss 0.005 Val mse 0.025\n",
      "Epoch 155 Train loss 0.005 Val mse 0.025\n",
      "Epoch 156 Train loss 0.005 Val mse 0.025\n",
      "Epoch 157 Train loss 0.005 Val mse 0.025\n",
      "Epoch 158 Train loss 0.006 Val mse 0.025\n",
      "Epoch 159 Train loss 0.005 Val mse 0.024\n",
      "Epoch 160 Train loss 0.005 Val mse 0.025\n",
      "Epoch 161 Train loss 0.005 Val mse 0.025\n",
      "Epoch 162 Train loss 0.005 Val mse 0.025\n",
      "Epoch 163 Train loss 0.005 Val mse 0.025\n",
      "Epoch 164 Train loss 0.006 Val mse 0.025\n",
      "Epoch 165 Train loss 0.005 Val mse 0.025\n",
      "Epoch 166 Train loss 0.005 Val mse 0.025\n",
      "Epoch 167 Train loss 0.005 Val mse 0.025\n",
      "Epoch 168 Train loss 0.005 Val mse 0.025\n",
      "Epoch 169 Train loss 0.006 Val mse 0.025\n",
      "Epoch 170 Train loss 0.005 Val mse 0.025\n",
      "Epoch 171 Train loss 0.005 Val mse 0.025\n",
      "Epoch 172 Train loss 0.005 Val mse 0.025\n",
      "Epoch 173 Train loss 0.005 Val mse 0.024\n",
      "Epoch 174 Train loss 0.006 Val mse 0.025\n",
      "Epoch 175 Train loss 0.005 Val mse 0.025\n",
      "Epoch 176 Train loss 0.005 Val mse 0.025\n",
      "Epoch 177 Train loss 0.005 Val mse 0.024\n",
      "Epoch 178 Train loss 0.005 Val mse 0.025\n",
      "Epoch 179 Train loss 0.005 Val mse 0.024\n",
      "Epoch 180 Train loss 0.005 Val mse 0.025\n",
      "Epoch 181 Train loss 0.006 Val mse 0.025\n",
      "Epoch 182 Train loss 0.006 Val mse 0.025\n",
      "Epoch 183 Train loss 0.005 Val mse 0.024\n",
      "Epoch 184 Train loss 0.005 Val mse 0.025\n",
      "Epoch 185 Train loss 0.006 Val mse 0.025\n",
      "Epoch 186 Train loss 0.005 Val mse 0.025\n",
      "Epoch 187 Train loss 0.005 Val mse 0.025\n",
      "Epoch 188 Train loss 0.005 Val mse 0.025\n",
      "Epoch 189 Train loss 0.005 Val mse 0.025\n",
      "Epoch 190 Train loss 0.006 Val mse 0.024\n",
      "Epoch 191 Train loss 0.005 Val mse 0.025\n",
      "Epoch 192 Train loss 0.006 Val mse 0.025\n",
      "Epoch 193 Train loss 0.005 Val mse 0.025\n",
      "Epoch 194 Train loss 0.005 Val mse 0.025\n",
      "Epoch 195 Train loss 0.005 Val mse 0.025\n",
      "Epoch 196 Train loss 0.005 Val mse 0.025\n",
      "Epoch 197 Train loss 0.005 Val mse 0.025\n",
      "Epoch 198 Train loss 0.006 Val mse 0.025\n",
      "Epoch 199 Train loss 0.005 Val mse 0.025\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "model = ScatResNet18().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "\n",
    "stats = {\n",
    "    'total_training_time': 0,\n",
    "    'loss': [],\n",
    "    'time_per_epoch': [],\n",
    "    'total_time_per_epoch': [],\n",
    "    'val_mse': [],\n",
    "    'min_val_mse': float('inf'),\n",
    "    'allocated_memory': [], # Memory currently used by Tensors\n",
    "    'reserved_memory': [], # Memory held by the PyTorch caching allocator\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    iteration_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration_losses.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_end_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    val_mse = calculate_mse(model, valloader, device)\n",
    "\n",
    "    # Track stats\n",
    "    if (epoch % 1) == 0:\n",
    "        stats['loss'].append(\n",
    "            np.mean(iteration_losses)\n",
    "        )\n",
    "        stats['val_mse'].append(\n",
    "            val_mse\n",
    "        )\n",
    "        stats['allocated_memory'].append(torch.cuda.memory_allocated())\n",
    "        stats['reserved_memory'].append(torch.cuda.memory_reserved())\n",
    "        stats['time_per_epoch'].append(epoch_end_time - epoch_start_time)\n",
    "        stats['total_time_per_epoch'].append(time.time() - start_time)\n",
    "\n",
    "    # Store best model\n",
    "    if (val_mse < stats['min_val_mse']):\n",
    "        if (val_mse < val_mse_storing_threshold):\n",
    "            stats['min_val_mse'] = val_mse\n",
    "            print('==> Saving model ...')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'mse':val_mse\n",
    "            }\n",
    "            save_path = checkpoint_dir / f\"{MODEL_NAME}_max_mse.pth\"\n",
    "            torch.save(state, save_path)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"DEBUG: One epoch time:\", time.time() - start_time)\n",
    "        print('DEBUG: ==> Saving model ...')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'mse':val_mse\n",
    "        }\n",
    "        save_path = checkpoint_dir / f\"{MODEL_NAME}_max_mse.pth\"\n",
    "        torch.save(state, save_path)\n",
    "        \n",
    "        \n",
    "    # Print progress\n",
    "    if (epoch % print_progress_every) == 0:\n",
    "        print(f\"Epoch {epoch} Train loss {stats['loss'][-1]:.3f} Val mse {stats['val_mse'][-1]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78aafc58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:02:35.007703Z",
     "iopub.status.busy": "2026-01-06T18:02:35.006854Z",
     "iopub.status.idle": "2026-01-06T18:02:47.528418Z",
     "shell.execute_reply": "2026-01-06T18:02:47.527583Z"
    },
    "papermill": {
     "duration": 12.534752,
     "end_time": "2026-01-06T18:02:47.530219",
     "exception": false,
     "start_time": "2026-01-06T18:02:34.995467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train mse is: 0.02434765560585156\n",
      "Final val mse is: 0.019559327512979507\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ScatResNet18().to(device)\n",
    "checkpoint = torch.load(checkpoint_dir / f\"{MODEL_NAME}_max_mse.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "\n",
    "stats['total_params'] = total_params\n",
    "stats['model_size_mb'] = model_size_mb\n",
    "stats['final_train_mse'] = calculate_mse(model, trainloader, device)\n",
    "stats['final_val_mse'] = calculate_mse(model, valloader, device)\n",
    "\n",
    "print(f'Final train mse is: {stats['final_train_mse']}')\n",
    "print(f'Final val mse is: {stats['final_val_mse']}')\n",
    "\n",
    "with open(training_stats_dir / f'{MODEL_NAME}_stats.pkl', 'wb') as file:\n",
    "        pickle.dump(stats, file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlKRvREyFsuJ9trrs14c5Y",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1945.926269,
   "end_time": "2026-01-06T18:02:50.543203",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T17:30:24.616934",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
