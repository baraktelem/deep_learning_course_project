{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253778f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:16:31.441226Z",
     "iopub.status.busy": "2026-01-01T12:16:31.440932Z",
     "iopub.status.idle": "2026-01-01T12:16:50.954799Z",
     "shell.execute_reply": "2026-01-01T12:16:50.953967Z"
    },
    "executionInfo": {
     "elapsed": 5636,
     "status": "ok",
     "timestamp": 1766743875913,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "zNf1AQxVkZdi",
    "outputId": "7fd9b195-abbc-4da1-f986-982016920821",
    "papermill": {
     "duration": 19.519961,
     "end_time": "2026-01-01T12:16:50.956563",
     "exception": false,
     "start_time": "2026-01-01T12:16:31.436602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.2)\r\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.10)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->kornia) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->kornia) (3.0.3)\r\n",
      "Collecting kymatio\r\n",
      "  Downloading kymatio-0.3.0-py3-none-any.whl.metadata (9.6 kB)\r\n",
      "Collecting appdirs (from kymatio)\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting configparser (from kymatio)\r\n",
      "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from kymatio) (2.0.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kymatio) (25.0)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from kymatio) (1.15.3)\r\n",
      "Downloading kymatio-0.3.0-py3-none-any.whl (87 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\r\n",
      "Installing collected packages: appdirs, configparser, kymatio\r\n",
      "Successfully installed appdirs-1.4.4 configparser-7.2.0 kymatio-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "!pip install kornia\n",
    "from kornia import augmentation as K\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!pip install kymatio\n",
    "from kymatio.torch import Scattering2D\n",
    "\n",
    "DEBUG = False\n",
    "MODEL_NAME = \"baseline_100_scat\"\n",
    "TRAIN_SIZE = 1000\n",
    "VALIDATION_SIZE = 5000\n",
    "env = 'kaggle' # 'kaggle' or 'colab'\n",
    "\n",
    "if env == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = Path('/content/drive/MyDrive/dl_pj')    \n",
    "elif env == 'kaggle':\n",
    "    base_dir = Path('/kaggle/working/')\n",
    "\n",
    "checkpoint_dir = base_dir / 'checkpoints'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "training_stats_dir = base_dir / 'stats'\n",
    "training_stats_dir.mkdir(parents=True, exist_ok=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2f8b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:16:50.964076Z",
     "iopub.status.busy": "2026-01-01T12:16:50.963395Z",
     "iopub.status.idle": "2026-01-01T12:16:50.975646Z",
     "shell.execute_reply": "2026-01-01T12:16:50.975058Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766743054230,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "ElgGUpWbrrci",
    "papermill": {
     "duration": 0.01763,
     "end_time": "2026-01-01T12:16:50.977090",
     "exception": false,
     "start_time": "2026-01-01T12:16:50.959460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, scattering_output_channels, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.scat_channels = scattering_output_channels\n",
    "        self.K = K\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=self.scat_channels, out_channels=self.scat_channels, groups=self.scat_channels, kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(scattering_output_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layer = []\n",
    "        for s in strides:\n",
    "            layer.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1, 16, 16)\n",
    "        x = self.deconv1(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18(scattering_output_channels):\n",
    "    return ResNet(scattering_output_channels, BasicBlock, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ad799f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:16:50.983197Z",
     "iopub.status.busy": "2026-01-01T12:16:50.982953Z",
     "iopub.status.idle": "2026-01-01T12:16:51.210227Z",
     "shell.execute_reply": "2026-01-01T12:16:51.209603Z"
    },
    "papermill": {
     "duration": 0.232316,
     "end_time": "2026-01-01T12:16:51.211959",
     "exception": false,
     "start_time": "2026-01-01T12:16:50.979643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scattering = Scattering2D(J=1, shape=(32, 32), max_order=1).to(device)\n",
    "scattering_output_channels = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ce6223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:16:51.218842Z",
     "iopub.status.busy": "2026-01-01T12:16:51.218261Z",
     "iopub.status.idle": "2026-01-01T12:16:51.316156Z",
     "shell.execute_reply": "2026-01-01T12:16:51.315230Z"
    },
    "papermill": {
     "duration": 0.102936,
     "end_time": "2026-01-01T12:16:51.317643",
     "exception": false,
     "start_time": "2026-01-01T12:16:51.214707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 11,187,921\n",
      "Model Size: 42.68 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_summary(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    total_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    size_mb = total_bytes / (1024 ** 2)\n",
    "    return num_params, size_mb\n",
    "\n",
    "total_params, model_size_mb = get_model_summary(ResNet18(scattering_output_channels))\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1193a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:16:51.324116Z",
     "iopub.status.busy": "2026-01-01T12:16:51.323883Z",
     "iopub.status.idle": "2026-01-01T12:16:51.328929Z",
     "shell.execute_reply": "2026-01-01T12:16:51.328360Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1766743013043,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "k3Z55XXW407W",
    "papermill": {
     "duration": 0.00985,
     "end_time": "2026-01-01T12:16:51.330260",
     "exception": false,
     "start_time": "2026-01-01T12:16:51.320410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval() # put in evaluation mode,  turn off Dropout, BatchNorm uses learned statistics\n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = normalize(images)\n",
    "            outputs = model(scattering(images))\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    return model_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589c7e4",
   "metadata": {
    "id": "kJ7YrZBl6lho",
    "papermill": {
     "duration": 0.002435,
     "end_time": "2026-01-01T12:16:51.335301",
     "exception": false,
     "start_time": "2026-01-01T12:16:51.332866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split data set into train-validation-test.\n",
    "We are using 80% train, 20% validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf866b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:16:51.341407Z",
     "iopub.status.busy": "2026-01-01T12:16:51.341008Z",
     "iopub.status.idle": "2026-01-01T12:17:00.905459Z",
     "shell.execute_reply": "2026-01-01T12:17:00.904858Z"
    },
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1766743016313,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "rkI3-MRt58hj",
    "papermill": {
     "duration": 9.569434,
     "end_time": "2026-01-01T12:17:00.907207",
     "exception": false,
     "start_time": "2026-01-01T12:16:51.337773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:05<00:00, 29.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 50000\n",
      "Train size: 1000\n",
      "Val size: 5000\n",
      "Samples per class Counter({np.int64(7): 100, np.int64(1): 100, np.int64(8): 100, np.int64(4): 100, np.int64(3): 100, np.int64(9): 100, np.int64(5): 100, np.int64(0): 100, np.int64(2): 100, np.int64(6): 100})\n",
      "Samples per class Counter({np.int64(1): 500, np.int64(9): 500, np.int64(2): 500, np.int64(4): 500, np.int64(6): 500, np.int64(5): 500, np.int64(0): 500, np.int64(3): 500, np.int64(8): 500, np.int64(7): 500})\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "# 80/20% split\n",
    "train_val_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "targets = np.array(train_val_set.targets)\n",
    "\n",
    "indices = np.arange(len(targets))\n",
    "train_indices, remaining_indices = train_test_split(\n",
    "    indices,\n",
    "    train_size=TRAIN_SIZE,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "validation_indices, _ = train_test_split(\n",
    "    remaining_indices,\n",
    "    train_size=VALIDATION_SIZE,\n",
    "    stratify=targets[remaining_indices],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "trainset = Subset(train_val_set, train_indices)\n",
    "valset = Subset(train_val_set, validation_indices)\n",
    "print(f\"Original size: {len(train_val_set)}\")\n",
    "print(f\"Train size: {len(trainset)}\")\n",
    "print(f\"Val size: {len(valset)}\")\n",
    "\n",
    "from collections import Counter \n",
    "subset_labels = [targets[i] for i in train_indices]\n",
    "print(\"Samples per class\", Counter(subset_labels))\n",
    "subset_labels = [targets[i] for i in validation_indices]\n",
    "print(\"Samples per class\", Counter(subset_labels))\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033ea79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:17:00.918215Z",
     "iopub.status.busy": "2026-01-01T12:17:00.917599Z",
     "iopub.status.idle": "2026-01-01T12:17:00.921621Z",
     "shell.execute_reply": "2026-01-01T12:17:00.920930Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1766743919319,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "Zy87RRrf7Vh6",
    "papermill": {
     "duration": 0.011052,
     "end_time": "2026-01-01T12:17:00.923131",
     "exception": false,
     "start_time": "2026-01-01T12:17:00.912079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "T_max = 200\n",
    "\n",
    "n_epochs = 1 if DEBUG else 200\n",
    "\n",
    "print_progress_every = 1\n",
    "val_accuracy_storing_threshold = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3b6cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:17:00.935242Z",
     "iopub.status.busy": "2026-01-01T12:17:00.934934Z",
     "iopub.status.idle": "2026-01-01T12:25:22.599456Z",
     "shell.execute_reply": "2026-01-01T12:25:22.598749Z"
    },
    "id": "W45Vot2zvrLE",
    "papermill": {
     "duration": 501.684611,
     "end_time": "2026-01-01T12:25:22.612346",
     "exception": false,
     "start_time": "2026-01-01T12:17:00.927735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 5.005 Val Acc 10.000\n",
      "Epoch 1 Loss 3.791 Val Acc 10.000\n",
      "Epoch 2 Loss 3.121 Val Acc 9.820\n",
      "Epoch 3 Loss 2.719 Val Acc 9.260\n",
      "Epoch 4 Loss 2.421 Val Acc 11.660\n",
      "Epoch 5 Loss 2.197 Val Acc 15.540\n",
      "Epoch 6 Loss 2.111 Val Acc 17.660\n",
      "Epoch 7 Loss 2.036 Val Acc 22.160\n",
      "Epoch 8 Loss 2.043 Val Acc 23.560\n",
      "Epoch 9 Loss 1.975 Val Acc 25.820\n",
      "Epoch 10 Loss 1.931 Val Acc 26.460\n",
      "Epoch 11 Loss 1.911 Val Acc 24.640\n",
      "Epoch 12 Loss 1.831 Val Acc 27.720\n",
      "Epoch 13 Loss 1.798 Val Acc 31.040\n",
      "Epoch 14 Loss 1.813 Val Acc 27.780\n",
      "Epoch 15 Loss 1.749 Val Acc 32.160\n",
      "Epoch 16 Loss 1.738 Val Acc 32.540\n",
      "Epoch 17 Loss 1.683 Val Acc 34.100\n",
      "Epoch 18 Loss 1.649 Val Acc 30.680\n",
      "Epoch 19 Loss 1.621 Val Acc 34.500\n",
      "Epoch 20 Loss 1.629 Val Acc 32.180\n",
      "Epoch 21 Loss 1.542 Val Acc 31.720\n",
      "Epoch 22 Loss 1.550 Val Acc 33.660\n",
      "Epoch 23 Loss 1.491 Val Acc 36.760\n",
      "Epoch 24 Loss 1.458 Val Acc 33.960\n",
      "Epoch 25 Loss 1.355 Val Acc 36.900\n",
      "Epoch 26 Loss 1.353 Val Acc 34.400\n",
      "Epoch 27 Loss 1.411 Val Acc 31.680\n",
      "Epoch 28 Loss 1.317 Val Acc 34.300\n",
      "Epoch 29 Loss 1.271 Val Acc 38.720\n",
      "Epoch 30 Loss 1.231 Val Acc 37.620\n",
      "Epoch 31 Loss 1.255 Val Acc 33.980\n",
      "Epoch 32 Loss 1.281 Val Acc 37.320\n",
      "Epoch 33 Loss 1.199 Val Acc 36.640\n",
      "Epoch 34 Loss 1.091 Val Acc 38.600\n",
      "Epoch 35 Loss 1.099 Val Acc 35.320\n",
      "Epoch 36 Loss 1.037 Val Acc 38.960\n",
      "Epoch 37 Loss 0.988 Val Acc 38.540\n",
      "Epoch 38 Loss 0.953 Val Acc 36.680\n",
      "Epoch 39 Loss 0.987 Val Acc 36.380\n",
      "==> Saving model ...\n",
      "Epoch 40 Loss 0.886 Val Acc 41.680\n",
      "Epoch 41 Loss 0.863 Val Acc 41.440\n",
      "Epoch 42 Loss 0.869 Val Acc 38.220\n",
      "Epoch 43 Loss 0.673 Val Acc 40.480\n",
      "Epoch 44 Loss 0.655 Val Acc 38.840\n",
      "Epoch 45 Loss 0.873 Val Acc 38.400\n",
      "Epoch 46 Loss 0.635 Val Acc 37.920\n",
      "Epoch 47 Loss 0.553 Val Acc 39.960\n",
      "Epoch 48 Loss 0.600 Val Acc 39.820\n",
      "Epoch 49 Loss 0.578 Val Acc 39.260\n",
      "Epoch 50 Loss 0.656 Val Acc 37.900\n",
      "Epoch 51 Loss 0.632 Val Acc 40.160\n",
      "Epoch 52 Loss 0.696 Val Acc 39.620\n",
      "Epoch 53 Loss 0.654 Val Acc 40.100\n",
      "Epoch 54 Loss 0.508 Val Acc 41.520\n",
      "Epoch 55 Loss 0.658 Val Acc 41.600\n",
      "==> Saving model ...\n",
      "Epoch 56 Loss 0.392 Val Acc 42.020\n",
      "Epoch 57 Loss 0.340 Val Acc 40.260\n",
      "Epoch 58 Loss 0.332 Val Acc 41.960\n",
      "Epoch 59 Loss 0.357 Val Acc 41.180\n",
      "Epoch 60 Loss 0.441 Val Acc 41.320\n",
      "==> Saving model ...\n",
      "Epoch 61 Loss 0.318 Val Acc 43.980\n",
      "Epoch 62 Loss 0.319 Val Acc 41.480\n",
      "Epoch 63 Loss 0.338 Val Acc 43.360\n",
      "Epoch 64 Loss 0.307 Val Acc 40.300\n",
      "Epoch 65 Loss 0.366 Val Acc 42.660\n",
      "==> Saving model ...\n",
      "Epoch 66 Loss 0.296 Val Acc 44.100\n",
      "==> Saving model ...\n",
      "Epoch 67 Loss 0.254 Val Acc 44.160\n",
      "==> Saving model ...\n",
      "Epoch 68 Loss 0.230 Val Acc 44.620\n",
      "Epoch 69 Loss 0.140 Val Acc 41.960\n",
      "==> Saving model ...\n",
      "Epoch 70 Loss 0.209 Val Acc 45.080\n",
      "==> Saving model ...\n",
      "Epoch 71 Loss 0.242 Val Acc 45.880\n",
      "Epoch 72 Loss 0.184 Val Acc 43.300\n",
      "Epoch 73 Loss 0.246 Val Acc 42.840\n",
      "Epoch 74 Loss 0.277 Val Acc 41.980\n",
      "Epoch 75 Loss 0.280 Val Acc 41.460\n",
      "Epoch 76 Loss 0.233 Val Acc 43.900\n",
      "Epoch 77 Loss 0.180 Val Acc 45.660\n",
      "Epoch 78 Loss 0.202 Val Acc 44.160\n",
      "Epoch 79 Loss 0.199 Val Acc 42.300\n",
      "Epoch 80 Loss 0.187 Val Acc 43.640\n",
      "Epoch 81 Loss 0.165 Val Acc 43.880\n",
      "Epoch 82 Loss 0.144 Val Acc 45.360\n",
      "Epoch 83 Loss 0.140 Val Acc 44.360\n",
      "Epoch 84 Loss 0.147 Val Acc 44.460\n",
      "Epoch 85 Loss 0.199 Val Acc 44.120\n",
      "Epoch 86 Loss 0.136 Val Acc 44.380\n",
      "Epoch 87 Loss 0.181 Val Acc 42.940\n",
      "Epoch 88 Loss 0.113 Val Acc 45.880\n",
      "Epoch 89 Loss 0.116 Val Acc 45.260\n",
      "Epoch 90 Loss 0.101 Val Acc 44.300\n",
      "Epoch 91 Loss 0.082 Val Acc 45.700\n",
      "Epoch 92 Loss 0.100 Val Acc 45.540\n",
      "==> Saving model ...\n",
      "Epoch 93 Loss 0.130 Val Acc 46.400\n",
      "Epoch 94 Loss 0.156 Val Acc 45.700\n",
      "Epoch 95 Loss 0.117 Val Acc 44.320\n",
      "Epoch 96 Loss 0.133 Val Acc 46.160\n",
      "Epoch 97 Loss 0.114 Val Acc 44.220\n",
      "Epoch 98 Loss 0.093 Val Acc 44.620\n",
      "==> Saving model ...\n",
      "Epoch 99 Loss 0.049 Val Acc 47.200\n",
      "Epoch 100 Loss 0.076 Val Acc 46.380\n",
      "Epoch 101 Loss 0.061 Val Acc 46.460\n",
      "Epoch 102 Loss 0.072 Val Acc 46.040\n",
      "==> Saving model ...\n",
      "Epoch 103 Loss 0.064 Val Acc 47.260\n",
      "Epoch 104 Loss 0.068 Val Acc 47.140\n",
      "==> Saving model ...\n",
      "Epoch 105 Loss 0.076 Val Acc 47.380\n",
      "==> Saving model ...\n",
      "Epoch 106 Loss 0.079 Val Acc 48.020\n",
      "Epoch 107 Loss 0.072 Val Acc 46.080\n",
      "Epoch 108 Loss 0.078 Val Acc 46.280\n",
      "Epoch 109 Loss 0.058 Val Acc 44.740\n",
      "Epoch 110 Loss 0.097 Val Acc 46.560\n",
      "Epoch 111 Loss 0.095 Val Acc 46.400\n",
      "Epoch 112 Loss 0.030 Val Acc 45.740\n",
      "Epoch 113 Loss 0.088 Val Acc 46.740\n",
      "Epoch 114 Loss 0.091 Val Acc 46.860\n",
      "Epoch 115 Loss 0.068 Val Acc 45.840\n",
      "Epoch 116 Loss 0.058 Val Acc 45.860\n",
      "Epoch 117 Loss 0.081 Val Acc 47.220\n",
      "Epoch 118 Loss 0.075 Val Acc 47.140\n",
      "Epoch 119 Loss 0.061 Val Acc 47.400\n",
      "Epoch 120 Loss 0.060 Val Acc 47.260\n",
      "Epoch 121 Loss 0.061 Val Acc 47.720\n",
      "Epoch 122 Loss 0.056 Val Acc 47.360\n",
      "Epoch 123 Loss 0.047 Val Acc 46.720\n",
      "Epoch 124 Loss 0.051 Val Acc 47.400\n",
      "Epoch 125 Loss 0.042 Val Acc 46.840\n",
      "Epoch 126 Loss 0.037 Val Acc 47.500\n",
      "==> Saving model ...\n",
      "Epoch 127 Loss 0.024 Val Acc 48.160\n",
      "==> Saving model ...\n",
      "Epoch 128 Loss 0.056 Val Acc 48.880\n",
      "Epoch 129 Loss 0.034 Val Acc 48.840\n",
      "Epoch 130 Loss 0.038 Val Acc 47.380\n",
      "Epoch 131 Loss 0.050 Val Acc 47.180\n",
      "Epoch 132 Loss 0.030 Val Acc 47.000\n",
      "Epoch 133 Loss 0.038 Val Acc 47.080\n",
      "Epoch 134 Loss 0.061 Val Acc 44.700\n",
      "Epoch 135 Loss 0.057 Val Acc 46.140\n",
      "Epoch 136 Loss 0.036 Val Acc 47.720\n",
      "Epoch 137 Loss 0.038 Val Acc 47.560\n",
      "Epoch 138 Loss 0.026 Val Acc 47.760\n",
      "Epoch 139 Loss 0.020 Val Acc 48.100\n",
      "Epoch 140 Loss 0.052 Val Acc 47.760\n",
      "Epoch 141 Loss 0.028 Val Acc 48.040\n",
      "Epoch 142 Loss 0.043 Val Acc 48.180\n",
      "Epoch 143 Loss 0.021 Val Acc 47.980\n",
      "Epoch 144 Loss 0.038 Val Acc 47.460\n",
      "Epoch 145 Loss 0.012 Val Acc 48.440\n",
      "Epoch 146 Loss 0.015 Val Acc 48.240\n",
      "Epoch 147 Loss 0.026 Val Acc 48.440\n",
      "Epoch 148 Loss 0.043 Val Acc 47.440\n",
      "Epoch 149 Loss 0.043 Val Acc 47.060\n",
      "Epoch 150 Loss 0.012 Val Acc 47.620\n",
      "Epoch 151 Loss 0.030 Val Acc 47.760\n",
      "Epoch 152 Loss 0.026 Val Acc 47.900\n",
      "Epoch 153 Loss 0.017 Val Acc 48.120\n",
      "Epoch 154 Loss 0.018 Val Acc 48.400\n",
      "Epoch 155 Loss 0.046 Val Acc 48.180\n",
      "Epoch 156 Loss 0.032 Val Acc 47.960\n",
      "Epoch 157 Loss 0.018 Val Acc 48.360\n",
      "Epoch 158 Loss 0.025 Val Acc 48.480\n",
      "Epoch 159 Loss 0.018 Val Acc 48.600\n",
      "Epoch 160 Loss 0.027 Val Acc 48.840\n",
      "Epoch 161 Loss 0.021 Val Acc 48.460\n",
      "Epoch 162 Loss 0.023 Val Acc 48.860\n",
      "==> Saving model ...\n",
      "Epoch 163 Loss 0.018 Val Acc 49.020\n",
      "==> Saving model ...\n",
      "Epoch 164 Loss 0.027 Val Acc 49.280\n",
      "Epoch 165 Loss 0.016 Val Acc 49.100\n",
      "Epoch 166 Loss 0.022 Val Acc 48.920\n",
      "Epoch 167 Loss 0.015 Val Acc 49.180\n",
      "Epoch 168 Loss 0.012 Val Acc 49.000\n",
      "Epoch 169 Loss 0.020 Val Acc 48.800\n",
      "Epoch 170 Loss 0.031 Val Acc 48.700\n",
      "Epoch 171 Loss 0.026 Val Acc 48.660\n",
      "Epoch 172 Loss 0.012 Val Acc 48.740\n",
      "Epoch 173 Loss 0.032 Val Acc 48.660\n",
      "Epoch 174 Loss 0.020 Val Acc 48.680\n",
      "Epoch 175 Loss 0.021 Val Acc 48.820\n",
      "Epoch 176 Loss 0.021 Val Acc 48.840\n",
      "Epoch 177 Loss 0.017 Val Acc 49.020\n",
      "Epoch 178 Loss 0.010 Val Acc 49.060\n",
      "Epoch 179 Loss 0.023 Val Acc 48.940\n",
      "Epoch 180 Loss 0.015 Val Acc 49.020\n",
      "Epoch 181 Loss 0.029 Val Acc 48.940\n",
      "Epoch 182 Loss 0.014 Val Acc 48.780\n",
      "Epoch 183 Loss 0.026 Val Acc 49.100\n",
      "Epoch 184 Loss 0.020 Val Acc 48.700\n",
      "Epoch 185 Loss 0.020 Val Acc 48.840\n",
      "Epoch 186 Loss 0.016 Val Acc 48.720\n",
      "Epoch 187 Loss 0.025 Val Acc 49.060\n",
      "Epoch 188 Loss 0.015 Val Acc 48.860\n",
      "Epoch 189 Loss 0.017 Val Acc 49.160\n",
      "Epoch 190 Loss 0.023 Val Acc 48.860\n",
      "Epoch 191 Loss 0.009 Val Acc 49.180\n",
      "Epoch 192 Loss 0.019 Val Acc 49.260\n",
      "Epoch 193 Loss 0.016 Val Acc 49.120\n",
      "Epoch 194 Loss 0.022 Val Acc 48.740\n",
      "Epoch 195 Loss 0.016 Val Acc 49.000\n",
      "Epoch 196 Loss 0.020 Val Acc 48.840\n",
      "Epoch 197 Loss 0.020 Val Acc 49.020\n",
      "Epoch 198 Loss 0.020 Val Acc 48.580\n",
      "Epoch 199 Loss 0.010 Val Acc 48.880\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465]).to(device)\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010]).to(device)\n",
    "normalize = K.Normalize(mean=mean, std=std)\n",
    "# define a sequence of augmentations\n",
    "aug_list = AugmentationSequential(\n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.2),\n",
    "    K.RandomResizedCrop(size=(32,32), scale=(0.7, 1.0), p=0.5),\n",
    "    normalize,\n",
    "    same_on_batch=False\n",
    ").to(device)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "model = ResNet18(scattering_output_channels).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "\n",
    "stats = {\n",
    "    'total_training_time': 0,\n",
    "    'loss': [],\n",
    "    'time_per_epoch': [],\n",
    "    'total_time_per_epoch': [],\n",
    "    'val_accuracy': [],\n",
    "    'max_val_accuracy': 0,\n",
    "    'allocated_memory': [], # Memory currently used by Tensors\n",
    "    'reserved_memory': [], # Memory held by the PyTorch caching allocator\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    iteration_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        inputs = aug_list(inputs)\n",
    "\n",
    "        outputs = model(scattering(inputs))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration_losses.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_end_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    val_accuracy = calculate_accuracy(model, valloader, device)\n",
    "\n",
    "    # Track stats\n",
    "    if (epoch % 1) == 0:\n",
    "        stats['loss'].append(\n",
    "            np.mean(iteration_losses)\n",
    "        )\n",
    "        stats['val_accuracy'].append(\n",
    "            val_accuracy\n",
    "        )\n",
    "        stats['allocated_memory'].append(torch.cuda.memory_allocated())\n",
    "        stats['reserved_memory'].append(torch.cuda.memory_reserved())\n",
    "        stats['time_per_epoch'].append(epoch_end_time - epoch_start_time)\n",
    "        stats['total_time_per_epoch'].append(time.time() - start_time)\n",
    "\n",
    "    # Store best model\n",
    "    if (val_accuracy > stats['max_val_accuracy']):\n",
    "        if (val_accuracy > val_accuracy_storing_threshold):\n",
    "            stats['max_val_accuracy'] = val_accuracy\n",
    "            print('==> Saving model ...')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'acc':val_accuracy\n",
    "            }\n",
    "            save_path = checkpoint_dir / f\"{MODEL_NAME}_max_acc.pth\"\n",
    "            torch.save(state, save_path)\n",
    "\n",
    "    if DEBUG:\n",
    "        print('==> Saving model ... DEBUG')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'acc':val_accuracy\n",
    "        }\n",
    "        save_path = checkpoint_dir / f\"{MODEL_NAME}_max_acc.pth\"\n",
    "        torch.save(state, save_path)\n",
    "        \n",
    "    # Print progress\n",
    "    if (epoch % print_progress_every) == 0:\n",
    "        print(f\"Epoch {epoch} Loss {stats['loss'][-1]:.3f} Val Acc {stats['val_accuracy'][-1]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2363ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:25:22.636427Z",
     "iopub.status.busy": "2026-01-01T12:25:22.635779Z",
     "iopub.status.idle": "2026-01-01T12:25:28.312450Z",
     "shell.execute_reply": "2026-01-01T12:25:28.311593Z"
    },
    "papermill": {
     "duration": 5.690681,
     "end_time": "2026-01-01T12:25:28.314166",
     "exception": false,
     "start_time": "2026-01-01T12:25:22.623485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy is: 49.85\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18(scattering_output_channels).to(device)\n",
    "checkpoint = torch.load(checkpoint_dir / f\"{MODEL_NAME}_max_acc.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "total_params, model_size_mb = get_model_summary(ResNet18(scattering_output_channels))\n",
    "stats['total_params'] = total_params\n",
    "stats['model_size_mb'] = model_size_mb\n",
    "stats['train_acc'] = calculate_accuracy(model, trainloader, device)\n",
    "stats['val_acc'] = calculate_accuracy(model, valloader, device)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "stats['test_acc'] = calculate_accuracy(model, testloader, device)\n",
    "\n",
    "with open(training_stats_dir / f'{MODEL_NAME}_stats.pkl', 'wb') as file:\n",
    "    pickle.dump(stats, file)\n",
    "\n",
    "print(f'Final test accuracy is: {stats['test_acc']}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlKRvREyFsuJ9trrs14c5Y",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 542.18514,
   "end_time": "2026-01-01T12:25:31.210478",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-01T12:16:29.025338",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
