{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5af1757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:06.983299Z",
     "iopub.status.busy": "2026-01-01T13:07:06.982994Z",
     "iopub.status.idle": "2026-01-01T13:07:27.906329Z",
     "shell.execute_reply": "2026-01-01T13:07:27.905311Z"
    },
    "executionInfo": {
     "elapsed": 5636,
     "status": "ok",
     "timestamp": 1766743875913,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "zNf1AQxVkZdi",
    "outputId": "7fd9b195-abbc-4da1-f986-982016920821",
    "papermill": {
     "duration": 20.92959,
     "end_time": "2026-01-01T13:07:27.908321",
     "exception": false,
     "start_time": "2026-01-01T13:07:06.978731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.2)\r\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.10)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->kornia) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->kornia) (3.0.3)\r\n",
      "Collecting kymatio\r\n",
      "  Downloading kymatio-0.3.0-py3-none-any.whl.metadata (9.6 kB)\r\n",
      "Collecting appdirs (from kymatio)\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting configparser (from kymatio)\r\n",
      "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from kymatio) (2.0.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kymatio) (25.0)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from kymatio) (1.15.3)\r\n",
      "Downloading kymatio-0.3.0-py3-none-any.whl (87 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\r\n",
      "Installing collected packages: appdirs, configparser, kymatio\r\n",
      "Successfully installed appdirs-1.4.4 configparser-7.2.0 kymatio-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "!pip install kornia\n",
    "from kornia import augmentation as K\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!pip install kymatio\n",
    "from kymatio.torch import Scattering2D\n",
    "\n",
    "DEBUG = False\n",
    "MODEL_NAME = \"baseline_100_scat_2\"\n",
    "TRAIN_SIZE = 1000\n",
    "VALIDATION_SIZE = 5000\n",
    "env = 'kaggle' # 'kaggle' or 'colab'\n",
    "\n",
    "if env == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_dir = Path('/content/drive/MyDrive/dl_pj')    \n",
    "elif env == 'kaggle':\n",
    "    base_dir = Path('/kaggle/working/')\n",
    "\n",
    "checkpoint_dir = base_dir / 'checkpoints'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "training_stats_dir = base_dir / 'stats'\n",
    "training_stats_dir.mkdir(parents=True, exist_ok=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d36e121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:27.916031Z",
     "iopub.status.busy": "2026-01-01T13:07:27.915350Z",
     "iopub.status.idle": "2026-01-01T13:07:27.927641Z",
     "shell.execute_reply": "2026-01-01T13:07:27.927017Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766743054230,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "ElgGUpWbrrci",
    "papermill": {
     "duration": 0.0177,
     "end_time": "2026-01-01T13:07:27.929018",
     "exception": false,
     "start_time": "2026-01-01T13:07:27.911318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, scattering_output_channels, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.scat_channels = scattering_output_channels\n",
    "        self.K = K\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=self.scat_channels, out_channels=self.scat_channels, groups=self.scat_channels, kernel_size=4, stride=4)\n",
    "        self.conv1 = nn.Conv2d(scattering_output_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layer = []\n",
    "        for s in strides:\n",
    "            layer.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1, 8, 8)\n",
    "        x = self.deconv1(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18(scattering_output_channels):\n",
    "    return ResNet(scattering_output_channels, BasicBlock, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739ee2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:27.935128Z",
     "iopub.status.busy": "2026-01-01T13:07:27.934902Z",
     "iopub.status.idle": "2026-01-01T13:07:28.249410Z",
     "shell.execute_reply": "2026-01-01T13:07:28.248755Z"
    },
    "papermill": {
     "duration": 0.319591,
     "end_time": "2026-01-01T13:07:28.251165",
     "exception": false,
     "start_time": "2026-01-01T13:07:27.931574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scattering = Scattering2D(J=2, shape=(32, 32), max_order=1).to(device)\n",
    "scattering_output_channels = 17*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2951ec0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:28.258402Z",
     "iopub.status.busy": "2026-01-01T13:07:28.258144Z",
     "iopub.status.idle": "2026-01-01T13:07:28.357848Z",
     "shell.execute_reply": "2026-01-01T13:07:28.356922Z"
    },
    "papermill": {
     "duration": 0.105295,
     "end_time": "2026-01-01T13:07:28.359366",
     "exception": false,
     "start_time": "2026-01-01T13:07:28.254071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 11,202,477\n",
      "Model Size: 42.73 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_summary(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    total_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    size_mb = total_bytes / (1024 ** 2)\n",
    "    return num_params, size_mb\n",
    "\n",
    "total_params, model_size_mb = get_model_summary(ResNet18(scattering_output_channels))\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8f18bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:28.366267Z",
     "iopub.status.busy": "2026-01-01T13:07:28.365656Z",
     "iopub.status.idle": "2026-01-01T13:07:28.370753Z",
     "shell.execute_reply": "2026-01-01T13:07:28.370060Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1766743013043,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "k3Z55XXW407W",
    "papermill": {
     "duration": 0.009953,
     "end_time": "2026-01-01T13:07:28.372143",
     "exception": false,
     "start_time": "2026-01-01T13:07:28.362190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval() # put in evaluation mode,  turn off Dropout, BatchNorm uses learned statistics\n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = normalize(images)\n",
    "            outputs = model(scattering(images))\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    return model_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c5e9f",
   "metadata": {
    "id": "kJ7YrZBl6lho",
    "papermill": {
     "duration": 0.002562,
     "end_time": "2026-01-01T13:07:28.377596",
     "exception": false,
     "start_time": "2026-01-01T13:07:28.375034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split data set into train-validation-test.\n",
    "We are using 80% train, 20% validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4336b4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:28.383819Z",
     "iopub.status.busy": "2026-01-01T13:07:28.383342Z",
     "iopub.status.idle": "2026-01-01T13:07:43.303608Z",
     "shell.execute_reply": "2026-01-01T13:07:43.303008Z"
    },
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1766743016313,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "rkI3-MRt58hj",
    "papermill": {
     "duration": 14.925221,
     "end_time": "2026-01-01T13:07:43.305334",
     "exception": false,
     "start_time": "2026-01-01T13:07:28.380113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:10<00:00, 16.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 50000\n",
      "Train size: 1000\n",
      "Val size: 5000\n",
      "Samples per class Counter({np.int64(7): 100, np.int64(1): 100, np.int64(8): 100, np.int64(4): 100, np.int64(3): 100, np.int64(9): 100, np.int64(5): 100, np.int64(0): 100, np.int64(2): 100, np.int64(6): 100})\n",
      "Samples per class Counter({np.int64(1): 500, np.int64(9): 500, np.int64(2): 500, np.int64(4): 500, np.int64(6): 500, np.int64(5): 500, np.int64(0): 500, np.int64(3): 500, np.int64(8): 500, np.int64(7): 500})\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "# 80/20% split\n",
    "train_val_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "targets = np.array(train_val_set.targets)\n",
    "\n",
    "indices = np.arange(len(targets))\n",
    "train_indices, remaining_indices = train_test_split(\n",
    "    indices,\n",
    "    train_size=TRAIN_SIZE,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "validation_indices, _ = train_test_split(\n",
    "    remaining_indices,\n",
    "    train_size=VALIDATION_SIZE,\n",
    "    stratify=targets[remaining_indices],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "trainset = Subset(train_val_set, train_indices)\n",
    "valset = Subset(train_val_set, validation_indices)\n",
    "print(f\"Original size: {len(train_val_set)}\")\n",
    "print(f\"Train size: {len(trainset)}\")\n",
    "print(f\"Val size: {len(valset)}\")\n",
    "\n",
    "from collections import Counter \n",
    "subset_labels = [targets[i] for i in train_indices]\n",
    "print(\"Samples per class\", Counter(subset_labels))\n",
    "subset_labels = [targets[i] for i in validation_indices]\n",
    "print(\"Samples per class\", Counter(subset_labels))\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61b3205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:43.316846Z",
     "iopub.status.busy": "2026-01-01T13:07:43.316389Z",
     "iopub.status.idle": "2026-01-01T13:07:43.320157Z",
     "shell.execute_reply": "2026-01-01T13:07:43.319620Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1766743919319,
     "user": {
      "displayName": "Gilad Navok",
      "userId": "06092819627906668279"
     },
     "user_tz": -120
    },
    "id": "Zy87RRrf7Vh6",
    "papermill": {
     "duration": 0.010964,
     "end_time": "2026-01-01T13:07:43.321364",
     "exception": false,
     "start_time": "2026-01-01T13:07:43.310400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "T_max = 200\n",
    "\n",
    "n_epochs = 1 if DEBUG else 200\n",
    "\n",
    "print_progress_every = 1\n",
    "val_accuracy_storing_threshold = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a097c06a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:07:43.332071Z",
     "iopub.status.busy": "2026-01-01T13:07:43.331814Z",
     "iopub.status.idle": "2026-01-01T13:16:44.081516Z",
     "shell.execute_reply": "2026-01-01T13:16:44.080663Z"
    },
    "id": "W45Vot2zvrLE",
    "papermill": {
     "duration": 540.757187,
     "end_time": "2026-01-01T13:16:44.083189",
     "exception": false,
     "start_time": "2026-01-01T13:07:43.326002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 4.382 Val Acc 10.000\n",
      "Epoch 1 Loss 3.782 Val Acc 10.000\n",
      "Epoch 2 Loss 2.889 Val Acc 10.240\n",
      "Epoch 3 Loss 2.697 Val Acc 13.660\n",
      "Epoch 4 Loss 2.701 Val Acc 13.720\n",
      "Epoch 5 Loss 2.386 Val Acc 15.060\n",
      "Epoch 6 Loss 2.232 Val Acc 14.500\n",
      "Epoch 7 Loss 2.089 Val Acc 20.300\n",
      "Epoch 8 Loss 2.025 Val Acc 20.120\n",
      "Epoch 9 Loss 1.967 Val Acc 25.940\n",
      "Epoch 10 Loss 1.934 Val Acc 28.300\n",
      "Epoch 11 Loss 1.873 Val Acc 29.560\n",
      "Epoch 12 Loss 1.815 Val Acc 28.260\n",
      "Epoch 13 Loss 1.809 Val Acc 29.240\n",
      "Epoch 14 Loss 1.814 Val Acc 30.520\n",
      "Epoch 15 Loss 1.750 Val Acc 31.840\n",
      "Epoch 16 Loss 1.684 Val Acc 32.300\n",
      "Epoch 17 Loss 1.691 Val Acc 32.360\n",
      "Epoch 18 Loss 1.661 Val Acc 32.360\n",
      "Epoch 19 Loss 1.642 Val Acc 29.600\n",
      "Epoch 20 Loss 1.637 Val Acc 31.340\n",
      "Epoch 21 Loss 1.656 Val Acc 30.380\n",
      "Epoch 22 Loss 1.543 Val Acc 32.000\n",
      "Epoch 23 Loss 1.519 Val Acc 35.200\n",
      "Epoch 24 Loss 1.503 Val Acc 32.960\n",
      "Epoch 25 Loss 1.507 Val Acc 35.920\n",
      "Epoch 26 Loss 1.423 Val Acc 35.320\n",
      "Epoch 27 Loss 1.447 Val Acc 33.400\n",
      "Epoch 28 Loss 1.412 Val Acc 33.820\n",
      "Epoch 29 Loss 1.372 Val Acc 34.580\n",
      "Epoch 30 Loss 1.404 Val Acc 33.880\n",
      "Epoch 31 Loss 1.359 Val Acc 38.680\n",
      "Epoch 32 Loss 1.256 Val Acc 38.760\n",
      "Epoch 33 Loss 1.254 Val Acc 34.520\n",
      "Epoch 34 Loss 1.304 Val Acc 38.860\n",
      "Epoch 35 Loss 1.196 Val Acc 35.680\n",
      "Epoch 36 Loss 1.177 Val Acc 39.280\n",
      "Epoch 37 Loss 1.104 Val Acc 35.280\n",
      "Epoch 38 Loss 1.148 Val Acc 35.280\n",
      "Epoch 39 Loss 1.040 Val Acc 30.740\n",
      "Epoch 40 Loss 0.980 Val Acc 38.660\n",
      "Epoch 41 Loss 1.072 Val Acc 38.200\n",
      "Epoch 42 Loss 1.034 Val Acc 38.300\n",
      "==> Saving model ...\n",
      "Epoch 43 Loss 0.917 Val Acc 40.740\n",
      "Epoch 44 Loss 0.844 Val Acc 37.580\n",
      "Epoch 45 Loss 0.887 Val Acc 36.760\n",
      "Epoch 46 Loss 0.884 Val Acc 38.600\n",
      "Epoch 47 Loss 0.796 Val Acc 39.300\n",
      "Epoch 48 Loss 0.764 Val Acc 37.420\n",
      "Epoch 49 Loss 0.596 Val Acc 38.300\n",
      "Epoch 50 Loss 0.596 Val Acc 40.260\n",
      "Epoch 51 Loss 0.653 Val Acc 40.380\n",
      "==> Saving model ...\n",
      "Epoch 52 Loss 0.600 Val Acc 41.740\n",
      "Epoch 53 Loss 0.542 Val Acc 41.000\n",
      "Epoch 54 Loss 0.514 Val Acc 40.800\n",
      "Epoch 55 Loss 0.573 Val Acc 34.720\n",
      "Epoch 56 Loss 0.688 Val Acc 34.620\n",
      "Epoch 57 Loss 0.598 Val Acc 36.620\n",
      "Epoch 58 Loss 0.526 Val Acc 35.580\n",
      "Epoch 59 Loss 0.410 Val Acc 41.660\n",
      "==> Saving model ...\n",
      "Epoch 60 Loss 0.427 Val Acc 42.000\n",
      "Epoch 61 Loss 0.403 Val Acc 39.600\n",
      "Epoch 62 Loss 0.412 Val Acc 40.180\n",
      "Epoch 63 Loss 0.428 Val Acc 41.100\n",
      "==> Saving model ...\n",
      "Epoch 64 Loss 0.381 Val Acc 43.820\n",
      "Epoch 65 Loss 0.292 Val Acc 43.520\n",
      "Epoch 66 Loss 0.227 Val Acc 41.020\n",
      "Epoch 67 Loss 0.255 Val Acc 42.040\n",
      "Epoch 68 Loss 0.266 Val Acc 42.480\n",
      "Epoch 69 Loss 0.249 Val Acc 40.340\n",
      "Epoch 70 Loss 0.292 Val Acc 41.660\n",
      "Epoch 71 Loss 0.231 Val Acc 42.380\n",
      "Epoch 72 Loss 0.220 Val Acc 41.340\n",
      "Epoch 73 Loss 0.266 Val Acc 43.740\n",
      "Epoch 74 Loss 0.249 Val Acc 43.000\n",
      "Epoch 75 Loss 0.263 Val Acc 40.640\n",
      "Epoch 76 Loss 0.136 Val Acc 41.300\n",
      "==> Saving model ...\n",
      "Epoch 77 Loss 0.287 Val Acc 44.620\n",
      "Epoch 78 Loss 0.144 Val Acc 43.560\n",
      "Epoch 79 Loss 0.183 Val Acc 42.760\n",
      "Epoch 80 Loss 0.175 Val Acc 43.900\n",
      "Epoch 81 Loss 0.217 Val Acc 43.520\n",
      "Epoch 82 Loss 0.171 Val Acc 41.720\n",
      "Epoch 83 Loss 0.250 Val Acc 42.760\n",
      "==> Saving model ...\n",
      "Epoch 84 Loss 0.176 Val Acc 47.060\n",
      "Epoch 85 Loss 0.141 Val Acc 40.640\n",
      "Epoch 86 Loss 0.169 Val Acc 43.820\n",
      "Epoch 87 Loss 0.133 Val Acc 44.020\n",
      "Epoch 88 Loss 0.149 Val Acc 45.900\n",
      "Epoch 89 Loss 0.142 Val Acc 43.320\n",
      "Epoch 90 Loss 0.070 Val Acc 43.600\n",
      "Epoch 91 Loss 0.103 Val Acc 43.740\n",
      "Epoch 92 Loss 0.112 Val Acc 44.000\n",
      "Epoch 93 Loss 0.101 Val Acc 45.440\n",
      "Epoch 94 Loss 0.115 Val Acc 45.240\n",
      "Epoch 95 Loss 0.108 Val Acc 42.920\n",
      "Epoch 96 Loss 0.098 Val Acc 44.200\n",
      "Epoch 97 Loss 0.135 Val Acc 46.020\n",
      "Epoch 98 Loss 0.105 Val Acc 44.820\n",
      "Epoch 99 Loss 0.098 Val Acc 45.740\n",
      "Epoch 100 Loss 0.064 Val Acc 46.160\n",
      "Epoch 101 Loss 0.096 Val Acc 45.460\n",
      "Epoch 102 Loss 0.087 Val Acc 43.480\n",
      "Epoch 103 Loss 0.111 Val Acc 43.540\n",
      "Epoch 104 Loss 0.142 Val Acc 46.320\n",
      "Epoch 105 Loss 0.067 Val Acc 46.440\n",
      "Epoch 106 Loss 0.106 Val Acc 44.640\n",
      "Epoch 107 Loss 0.114 Val Acc 43.880\n",
      "Epoch 108 Loss 0.087 Val Acc 45.440\n",
      "Epoch 109 Loss 0.078 Val Acc 46.560\n",
      "Epoch 110 Loss 0.070 Val Acc 45.860\n",
      "Epoch 111 Loss 0.056 Val Acc 46.060\n",
      "Epoch 112 Loss 0.074 Val Acc 46.760\n",
      "Epoch 113 Loss 0.048 Val Acc 46.440\n",
      "Epoch 114 Loss 0.047 Val Acc 44.800\n",
      "Epoch 115 Loss 0.041 Val Acc 45.660\n",
      "Epoch 116 Loss 0.026 Val Acc 46.640\n",
      "Epoch 117 Loss 0.035 Val Acc 45.760\n",
      "Epoch 118 Loss 0.070 Val Acc 46.760\n",
      "==> Saving model ...\n",
      "Epoch 119 Loss 0.063 Val Acc 47.320\n",
      "Epoch 120 Loss 0.057 Val Acc 45.920\n",
      "Epoch 121 Loss 0.030 Val Acc 45.600\n",
      "Epoch 122 Loss 0.066 Val Acc 46.200\n",
      "Epoch 123 Loss 0.019 Val Acc 46.560\n",
      "Epoch 124 Loss 0.029 Val Acc 47.320\n",
      "Epoch 125 Loss 0.043 Val Acc 46.800\n",
      "Epoch 126 Loss 0.049 Val Acc 47.120\n",
      "Epoch 127 Loss 0.036 Val Acc 46.300\n",
      "Epoch 128 Loss 0.049 Val Acc 45.580\n",
      "Epoch 129 Loss 0.035 Val Acc 46.080\n",
      "Epoch 130 Loss 0.050 Val Acc 47.140\n",
      "Epoch 131 Loss 0.049 Val Acc 47.220\n",
      "Epoch 132 Loss 0.055 Val Acc 47.220\n",
      "==> Saving model ...\n",
      "Epoch 133 Loss 0.048 Val Acc 47.700\n",
      "Epoch 134 Loss 0.050 Val Acc 47.540\n",
      "Epoch 135 Loss 0.020 Val Acc 47.360\n",
      "Epoch 136 Loss 0.055 Val Acc 47.600\n",
      "Epoch 137 Loss 0.029 Val Acc 46.960\n",
      "Epoch 138 Loss 0.034 Val Acc 47.440\n",
      "Epoch 139 Loss 0.050 Val Acc 47.140\n",
      "Epoch 140 Loss 0.070 Val Acc 47.180\n",
      "Epoch 141 Loss 0.014 Val Acc 47.340\n",
      "==> Saving model ...\n",
      "Epoch 142 Loss 0.048 Val Acc 48.000\n",
      "==> Saving model ...\n",
      "Epoch 143 Loss 0.039 Val Acc 48.080\n",
      "Epoch 144 Loss 0.047 Val Acc 47.780\n",
      "Epoch 145 Loss 0.031 Val Acc 47.100\n",
      "Epoch 146 Loss 0.033 Val Acc 46.280\n",
      "Epoch 147 Loss 0.018 Val Acc 46.700\n",
      "Epoch 148 Loss 0.039 Val Acc 46.640\n",
      "Epoch 149 Loss 0.024 Val Acc 47.180\n",
      "Epoch 150 Loss 0.033 Val Acc 47.480\n",
      "Epoch 151 Loss 0.014 Val Acc 47.960\n",
      "Epoch 152 Loss 0.008 Val Acc 47.900\n",
      "Epoch 153 Loss 0.008 Val Acc 48.040\n",
      "Epoch 154 Loss 0.044 Val Acc 48.020\n",
      "==> Saving model ...\n",
      "Epoch 155 Loss 0.010 Val Acc 48.400\n",
      "==> Saving model ...\n",
      "Epoch 156 Loss 0.016 Val Acc 48.640\n",
      "Epoch 157 Loss 0.030 Val Acc 47.920\n",
      "Epoch 158 Loss 0.016 Val Acc 48.240\n",
      "Epoch 159 Loss 0.023 Val Acc 48.220\n",
      "Epoch 160 Loss 0.015 Val Acc 48.420\n",
      "Epoch 161 Loss 0.014 Val Acc 48.280\n",
      "Epoch 162 Loss 0.022 Val Acc 48.160\n",
      "Epoch 163 Loss 0.012 Val Acc 48.360\n",
      "Epoch 164 Loss 0.010 Val Acc 48.160\n",
      "Epoch 165 Loss 0.029 Val Acc 48.420\n",
      "Epoch 166 Loss 0.015 Val Acc 48.580\n",
      "==> Saving model ...\n",
      "Epoch 167 Loss 0.021 Val Acc 48.700\n",
      "Epoch 168 Loss 0.018 Val Acc 48.540\n",
      "==> Saving model ...\n",
      "Epoch 169 Loss 0.011 Val Acc 48.740\n",
      "Epoch 170 Loss 0.024 Val Acc 48.700\n",
      "Epoch 171 Loss 0.028 Val Acc 48.660\n",
      "Epoch 172 Loss 0.018 Val Acc 48.400\n",
      "Epoch 173 Loss 0.018 Val Acc 48.240\n",
      "Epoch 174 Loss 0.007 Val Acc 48.400\n",
      "Epoch 175 Loss 0.031 Val Acc 47.960\n",
      "Epoch 176 Loss 0.020 Val Acc 48.380\n",
      "Epoch 177 Loss 0.005 Val Acc 48.580\n",
      "==> Saving model ...\n",
      "Epoch 178 Loss 0.012 Val Acc 48.820\n",
      "==> Saving model ...\n",
      "Epoch 179 Loss 0.019 Val Acc 48.840\n",
      "Epoch 180 Loss 0.016 Val Acc 48.400\n",
      "Epoch 181 Loss 0.020 Val Acc 48.400\n",
      "Epoch 182 Loss 0.015 Val Acc 48.380\n",
      "Epoch 183 Loss 0.013 Val Acc 48.300\n",
      "Epoch 184 Loss 0.009 Val Acc 48.780\n",
      "Epoch 185 Loss 0.024 Val Acc 48.780\n",
      "==> Saving model ...\n",
      "Epoch 186 Loss 0.010 Val Acc 48.940\n",
      "Epoch 187 Loss 0.010 Val Acc 48.800\n",
      "Epoch 188 Loss 0.018 Val Acc 48.780\n",
      "Epoch 189 Loss 0.018 Val Acc 48.580\n",
      "Epoch 190 Loss 0.015 Val Acc 48.520\n",
      "Epoch 191 Loss 0.008 Val Acc 48.840\n",
      "Epoch 192 Loss 0.026 Val Acc 48.600\n",
      "Epoch 193 Loss 0.017 Val Acc 48.500\n",
      "Epoch 194 Loss 0.013 Val Acc 48.660\n",
      "Epoch 195 Loss 0.027 Val Acc 48.660\n",
      "Epoch 196 Loss 0.008 Val Acc 48.860\n",
      "==> Saving model ...\n",
      "Epoch 197 Loss 0.012 Val Acc 48.960\n",
      "Epoch 198 Loss 0.021 Val Acc 48.660\n",
      "Epoch 199 Loss 0.014 Val Acc 48.620\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465]).to(device)\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010]).to(device)\n",
    "normalize = K.Normalize(mean=mean, std=std)\n",
    "# define a sequence of augmentations\n",
    "aug_list = AugmentationSequential(\n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.2),\n",
    "    K.RandomResizedCrop(size=(32,32), scale=(0.7, 1.0), p=0.5),\n",
    "    normalize,\n",
    "    same_on_batch=False\n",
    ").to(device)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "model = ResNet18(scattering_output_channels).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "\n",
    "stats = {\n",
    "    'total_training_time': 0,\n",
    "    'loss': [],\n",
    "    'time_per_epoch': [],\n",
    "    'total_time_per_epoch': [],\n",
    "    'val_accuracy': [],\n",
    "    'max_val_accuracy': 0,\n",
    "    'allocated_memory': [], # Memory currently used by Tensors\n",
    "    'reserved_memory': [], # Memory held by the PyTorch caching allocator\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    iteration_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        inputs = aug_list(inputs)\n",
    "\n",
    "        outputs = model(scattering(inputs))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration_losses.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_end_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    val_accuracy = calculate_accuracy(model, valloader, device)\n",
    "\n",
    "    # Track stats\n",
    "    if (epoch % 1) == 0:\n",
    "        stats['loss'].append(\n",
    "            np.mean(iteration_losses)\n",
    "        )\n",
    "        stats['val_accuracy'].append(\n",
    "            val_accuracy\n",
    "        )\n",
    "        stats['allocated_memory'].append(torch.cuda.memory_allocated())\n",
    "        stats['reserved_memory'].append(torch.cuda.memory_reserved())\n",
    "        stats['time_per_epoch'].append(epoch_end_time - epoch_start_time)\n",
    "        stats['total_time_per_epoch'].append(time.time() - start_time)\n",
    "\n",
    "    # Store best model\n",
    "    if (val_accuracy > stats['max_val_accuracy']):\n",
    "        if (val_accuracy > val_accuracy_storing_threshold):\n",
    "            stats['max_val_accuracy'] = val_accuracy\n",
    "            print('==> Saving model ...')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'acc':val_accuracy\n",
    "            }\n",
    "            save_path = checkpoint_dir / f\"{MODEL_NAME}_max_acc.pth\"\n",
    "            torch.save(state, save_path)\n",
    "\n",
    "    if DEBUG:\n",
    "        print('==> Saving model ... DEBUG')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'acc':val_accuracy\n",
    "        }\n",
    "        save_path = checkpoint_dir / f\"{MODEL_NAME}_max_acc.pth\"\n",
    "        torch.save(state, save_path)\n",
    "        \n",
    "    # Print progress\n",
    "    if (epoch % print_progress_every) == 0:\n",
    "        print(f\"Epoch {epoch} Loss {stats['loss'][-1]:.3f} Val Acc {stats['val_accuracy'][-1]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a82d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T13:16:44.109614Z",
     "iopub.status.busy": "2026-01-01T13:16:44.108962Z",
     "iopub.status.idle": "2026-01-01T13:16:50.170194Z",
     "shell.execute_reply": "2026-01-01T13:16:50.169441Z"
    },
    "papermill": {
     "duration": 6.076421,
     "end_time": "2026-01-01T13:16:50.171613",
     "exception": false,
     "start_time": "2026-01-01T13:16:44.095192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy is: 49.18\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18(scattering_output_channels).to(device)\n",
    "checkpoint = torch.load(checkpoint_dir / f\"{MODEL_NAME}_max_acc.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "total_params, model_size_mb = get_model_summary(ResNet18(scattering_output_channels))\n",
    "stats['total_params'] = total_params\n",
    "stats['model_size_mb'] = model_size_mb\n",
    "stats['train_acc'] = calculate_accuracy(model, trainloader, device)\n",
    "stats['val_acc'] = calculate_accuracy(model, valloader, device)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "stats['test_acc'] = calculate_accuracy(model, testloader, device)\n",
    "\n",
    "with open(training_stats_dir / f'{MODEL_NAME}_stats.pkl', 'wb') as file:\n",
    "    pickle.dump(stats, file)\n",
    "\n",
    "print(f'Final test accuracy is: {stats['test_acc']}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlKRvREyFsuJ9trrs14c5Y",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 588.267866,
   "end_time": "2026-01-01T13:16:52.747600",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-01T13:07:04.479734",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
